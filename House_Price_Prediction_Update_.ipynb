{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "House Price Prediction Update .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appy09/regression/blob/main/House_Price_Prediction_Update_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSrkMULGWKBv",
        "outputId": "0f24e0d2-3a1a-4fa0-b72c-c0e416651c6e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "## for feature slection\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# to visualise al the columns in the dataframe\n",
        "pd.pandas.set_option('display.max_columns', None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
            "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
            "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
            "In C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
            "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
            "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
            "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
            "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
            "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYUWO0UOWKBz"
      },
      "source": [
        "dataset=pd.read_csv('X_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq1UrGleWKB1",
        "outputId": "ccb37494-0d3d-4612-b8e0-a2c35f310a60"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>LotFrontagenan</th>\n",
              "      <th>MasVnrAreanan</th>\n",
              "      <th>GarageYrBltnan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>12.247694</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.418208</td>\n",
              "      <td>0.366344</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.036765</td>\n",
              "      <td>0.098361</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.12250</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.125089</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.064212</td>\n",
              "      <td>0.140098</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.356155</td>\n",
              "      <td>0.413559</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.577712</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.046729</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.386460</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111517</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>12.109011</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.495064</td>\n",
              "      <td>0.391317</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.227941</td>\n",
              "      <td>0.524590</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.173281</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.121575</td>\n",
              "      <td>0.206547</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.503056</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.470245</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.289720</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.324401</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.347725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>12.317167</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.434909</td>\n",
              "      <td>0.422359</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.051471</td>\n",
              "      <td>0.114754</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.10125</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.086109</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.185788</td>\n",
              "      <td>0.150573</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.383441</td>\n",
              "      <td>0.419370</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.593095</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.065421</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.428773</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076782</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>11.849398</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.388581</td>\n",
              "      <td>0.390295</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.669118</td>\n",
              "      <td>0.606557</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.038271</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.231164</td>\n",
              "      <td>0.123732</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.399941</td>\n",
              "      <td>0.366102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.579157</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.074766</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.452750</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.063985</td>\n",
              "      <td>0.492754</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>12.429216</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.513123</td>\n",
              "      <td>0.468761</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.147541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.21875</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.116052</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209760</td>\n",
              "      <td>0.187398</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.466237</td>\n",
              "      <td>0.509927</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666523</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.074766</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.589563</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.224037</td>\n",
              "      <td>0.153565</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SalePrice  MSSubClass  MSZoning  LotFrontage   LotArea  Street  Alley  \\\n",
              "0   1  12.247694    0.235294      0.75     0.418208  0.366344     1.0    1.0   \n",
              "1   2  12.109011    0.000000      0.75     0.495064  0.391317     1.0    1.0   \n",
              "2   3  12.317167    0.235294      0.75     0.434909  0.422359     1.0    1.0   \n",
              "3   4  11.849398    0.294118      0.75     0.388581  0.390295     1.0    1.0   \n",
              "4   5  12.429216    0.235294      0.75     0.513123  0.468761     1.0    1.0   \n",
              "\n",
              "   LotShape  LandContour  Utilities  LotConfig  LandSlope  Neighborhood  \\\n",
              "0  0.000000     0.333333        1.0       0.00        0.0      0.636364   \n",
              "1  0.000000     0.333333        1.0       0.50        0.0      0.500000   \n",
              "2  0.333333     0.333333        1.0       0.00        0.0      0.636364   \n",
              "3  0.333333     0.333333        1.0       0.25        0.0      0.727273   \n",
              "4  0.333333     0.333333        1.0       0.50        0.0      1.000000   \n",
              "\n",
              "   Condition1  Condition2  BldgType  HouseStyle  OverallQual  OverallCond  \\\n",
              "0         0.4         1.0      0.75         1.0     0.666667        0.500   \n",
              "1         0.2         1.0      0.75         0.6     0.555556        0.875   \n",
              "2         0.4         1.0      0.75         1.0     0.666667        0.500   \n",
              "3         0.4         1.0      0.75         1.0     0.666667        0.500   \n",
              "4         0.4         1.0      0.75         1.0     0.777778        0.500   \n",
              "\n",
              "   YearBuilt  YearRemodAdd  RoofStyle  RoofMatl  Exterior1st  Exterior2nd  \\\n",
              "0   0.036765      0.098361        0.0       0.0          1.0          1.0   \n",
              "1   0.227941      0.524590        0.0       0.0          0.4          0.3   \n",
              "2   0.051471      0.114754        0.0       0.0          1.0          1.0   \n",
              "3   0.669118      0.606557        0.0       0.0          0.2          0.4   \n",
              "4   0.058824      0.147541        0.0       0.0          1.0          1.0   \n",
              "\n",
              "   MasVnrType  MasVnrArea  ExterQual  ExterCond  Foundation  BsmtQual  \\\n",
              "0        0.50     0.12250   0.666667        1.0        1.00      0.75   \n",
              "1        0.25     0.00000   0.333333        1.0        0.50      0.75   \n",
              "2        0.50     0.10125   0.666667        1.0        1.00      0.75   \n",
              "3        0.25     0.00000   0.333333        1.0        0.25      0.50   \n",
              "4        0.50     0.21875   0.666667        1.0        1.00      0.75   \n",
              "\n",
              "   BsmtCond  BsmtExposure  BsmtFinType1  BsmtFinSF1  BsmtFinType2  BsmtFinSF2  \\\n",
              "0      0.75          0.25      1.000000    0.125089      0.833333         0.0   \n",
              "1      0.75          1.00      0.666667    0.173281      0.833333         0.0   \n",
              "2      0.75          0.50      1.000000    0.086109      0.833333         0.0   \n",
              "3      1.00          0.25      0.666667    0.038271      0.833333         0.0   \n",
              "4      0.75          0.75      1.000000    0.116052      0.833333         0.0   \n",
              "\n",
              "   BsmtUnfSF  TotalBsmtSF  Heating  HeatingQC  CentralAir  Electrical  \\\n",
              "0   0.064212     0.140098      1.0       1.00         1.0         1.0   \n",
              "1   0.121575     0.206547      1.0       1.00         1.0         1.0   \n",
              "2   0.185788     0.150573      1.0       1.00         1.0         1.0   \n",
              "3   0.231164     0.123732      1.0       0.75         1.0         1.0   \n",
              "4   0.209760     0.187398      1.0       1.00         1.0         1.0   \n",
              "\n",
              "   1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  BsmtHalfBath  \\\n",
              "0  0.356155  0.413559           0.0   0.577712      0.333333           0.0   \n",
              "1  0.503056  0.000000           0.0   0.470245      0.000000           0.5   \n",
              "2  0.383441  0.419370           0.0   0.593095      0.333333           0.0   \n",
              "3  0.399941  0.366102           0.0   0.579157      0.333333           0.0   \n",
              "4  0.466237  0.509927           0.0   0.666523      0.333333           0.0   \n",
              "\n",
              "   FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  KitchenQual  TotRmsAbvGrd  \\\n",
              "0  0.666667       0.5         0.375      0.333333     0.666667      0.500000   \n",
              "1  0.666667       0.0         0.375      0.333333     0.333333      0.333333   \n",
              "2  0.666667       0.5         0.375      0.333333     0.666667      0.333333   \n",
              "3  0.333333       0.0         0.375      0.333333     0.666667      0.416667   \n",
              "4  0.666667       0.5         0.500      0.333333     0.666667      0.583333   \n",
              "\n",
              "   Functional  Fireplaces  FireplaceQu  GarageType  GarageYrBlt  GarageFinish  \\\n",
              "0         1.0    0.000000          0.2         0.8     0.046729      0.666667   \n",
              "1         1.0    0.333333          0.6         0.8     0.289720      0.666667   \n",
              "2         1.0    0.333333          0.6         0.8     0.065421      0.666667   \n",
              "3         1.0    0.333333          0.8         0.4     0.074766      0.333333   \n",
              "4         1.0    0.333333          0.6         0.8     0.074766      0.666667   \n",
              "\n",
              "   GarageCars  GarageArea  GarageQual  GarageCond  PavedDrive  WoodDeckSF  \\\n",
              "0        0.50    0.386460    0.666667         1.0         1.0    0.000000   \n",
              "1        0.50    0.324401    0.666667         1.0         1.0    0.347725   \n",
              "2        0.50    0.428773    0.666667         1.0         1.0    0.000000   \n",
              "3        0.75    0.452750    0.666667         1.0         1.0    0.000000   \n",
              "4        0.75    0.589563    0.666667         1.0         1.0    0.224037   \n",
              "\n",
              "   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  PoolQC  \\\n",
              "0     0.111517       0.000000        0.0          0.0       0.0     0.0   \n",
              "1     0.000000       0.000000        0.0          0.0       0.0     0.0   \n",
              "2     0.076782       0.000000        0.0          0.0       0.0     0.0   \n",
              "3     0.063985       0.492754        0.0          0.0       0.0     0.0   \n",
              "4     0.153565       0.000000        0.0          0.0       0.0     0.0   \n",
              "\n",
              "   Fence  MiscFeature  MiscVal    MoSold  YrSold  SaleType  SaleCondition  \\\n",
              "0    1.0          1.0      0.0  0.090909    0.50  0.666667           0.75   \n",
              "1    1.0          1.0      0.0  0.363636    0.25  0.666667           0.75   \n",
              "2    1.0          1.0      0.0  0.727273    0.50  0.666667           0.75   \n",
              "3    1.0          1.0      0.0  0.090909    0.00  0.666667           0.00   \n",
              "4    1.0          1.0      0.0  1.000000    0.50  0.666667           0.75   \n",
              "\n",
              "   LotFrontagenan  MasVnrAreanan  GarageYrBltnan  \n",
              "0             0.0            0.0             0.0  \n",
              "1             0.0            0.0             0.0  \n",
              "2             0.0            0.0             0.0  \n",
              "3             0.0            0.0             0.0  \n",
              "4             0.0            0.0             0.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oVitaAZWKB4"
      },
      "source": [
        "## Capture the dependent feature\n",
        "y_train=dataset[['SalePrice']]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gD83698WKB6"
      },
      "source": [
        "## drop dependent feature from dataset\n",
        "X_train=dataset.drop(['Id','SalePrice'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JkUbZJUWKB-",
        "outputId": "22256749-46d2-4a6f-aab9-e3a0e60286c4"
      },
      "source": [
        "### Apply Feature Selection\n",
        "# first, I specify the Lasso Regression model, and I\n",
        "# select a suitable alpha (equivalent of penalty).\n",
        "# The bigger the alpha the less features that will be selected.\n",
        "\n",
        "# Then I use the selectFromModel object from sklearn, which\n",
        "# will select the features which coefficients are non-zero\n",
        "\n",
        "feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function\n",
        "feature_sel_model.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=Lasso(alpha=0.005, copy_X=True, fit_intercept=True,\n",
              "                                max_iter=1000, normalize=False, positive=False,\n",
              "                                precompute=False, random_state=0,\n",
              "                                selection='cyclic', tol=0.0001,\n",
              "                                warm_start=False),\n",
              "                max_features=None, norm_order=1, prefit=False, threshold=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni1QjvgyWKCA",
        "outputId": "65e108b5-3176-4888-a1c2-e73636942fd9"
      },
      "source": [
        "feature_sel_model.get_support()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False, False, False, False, False, False, False,\n",
              "       False, False,  True, False, False, False, False,  True, False,\n",
              "       False,  True,  True, False, False, False, False, False, False,\n",
              "       False, False,  True, False,  True, False, False, False, False,\n",
              "       False, False, False,  True,  True, False,  True, False, False,\n",
              "        True,  True, False, False, False, False, False,  True, False,\n",
              "       False,  True,  True,  True, False,  True,  True, False, False,\n",
              "       False,  True, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False,  True, False, False,\n",
              "       False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkKGuAHIWKCD",
        "outputId": "772c2a65-5210-46d1-8eb9-fcd88748ec3f"
      },
      "source": [
        "# let's print the number of total and selected features\n",
        "\n",
        "# this is how we can make a list of the selected features\n",
        "selected_feat = X_train.columns[(feature_sel_model.get_support())]\n",
        "\n",
        "# let's print some stats\n",
        "print('total features: {}'.format((X_train.shape[1])))\n",
        "print('selected features: {}'.format(len(selected_feat)))\n",
        "#try which features has been discarded\n",
        "#print('features with coefficients shrank to zero: {}'.format(np.sum(sel_.estimator_.coef_ == 0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total features: 82\n",
            "selected features: 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROCdrp3zWKCF",
        "outputId": "46d88cd1-dd4b-4e28-b3af-f97a92e5fe44"
      },
      "source": [
        "selected_feat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MSSubClass', 'MSZoning', 'Neighborhood', 'OverallQual', 'YearRemodAdd',\n",
              "       'RoofStyle', 'BsmtQual', 'BsmtExposure', 'HeatingQC', 'CentralAir',\n",
              "       '1stFlrSF', 'GrLivArea', 'BsmtFullBath', 'KitchenQual', 'Fireplaces',\n",
              "       'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageCars', 'PavedDrive',\n",
              "       'SaleCondition'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU9aU7NZWKCI"
      },
      "source": [
        "X_train=X_train[selected_feat]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo-GtvmrWKCK",
        "outputId": "d69bb178-9475-40a4-fa8d-31bf531037ff"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.098361</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.356155</td>\n",
              "      <td>0.577712</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.524590</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.503056</td>\n",
              "      <td>0.470245</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.114754</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.383441</td>\n",
              "      <td>0.593095</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.606557</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.399941</td>\n",
              "      <td>0.579157</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.147541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.466237</td>\n",
              "      <td>0.666523</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MSSubClass  MSZoning  Neighborhood  OverallQual  YearRemodAdd  RoofStyle  \\\n",
              "0    0.235294      0.75      0.636364     0.666667      0.098361        0.0   \n",
              "1    0.000000      0.75      0.500000     0.555556      0.524590        0.0   \n",
              "2    0.235294      0.75      0.636364     0.666667      0.114754        0.0   \n",
              "3    0.294118      0.75      0.727273     0.666667      0.606557        0.0   \n",
              "4    0.235294      0.75      1.000000     0.777778      0.147541        0.0   \n",
              "\n",
              "   BsmtQual  BsmtExposure  HeatingQC  CentralAir  1stFlrSF  GrLivArea  \\\n",
              "0      0.75          0.25       1.00         1.0  0.356155   0.577712   \n",
              "1      0.75          1.00       1.00         1.0  0.503056   0.470245   \n",
              "2      0.75          0.50       1.00         1.0  0.383441   0.593095   \n",
              "3      0.50          0.25       0.75         1.0  0.399941   0.579157   \n",
              "4      0.75          0.75       1.00         1.0  0.466237   0.666523   \n",
              "\n",
              "   BsmtFullBath  KitchenQual  Fireplaces  FireplaceQu  GarageType  \\\n",
              "0      0.333333     0.666667    0.000000          0.2         0.8   \n",
              "1      0.000000     0.333333    0.333333          0.6         0.8   \n",
              "2      0.333333     0.666667    0.333333          0.6         0.8   \n",
              "3      0.333333     0.666667    0.333333          0.8         0.4   \n",
              "4      0.333333     0.666667    0.333333          0.6         0.8   \n",
              "\n",
              "   GarageFinish  GarageCars  PavedDrive  SaleCondition  \n",
              "0      0.666667        0.50         1.0           0.75  \n",
              "1      0.666667        0.50         1.0           0.75  \n",
              "2      0.666667        0.50         1.0           0.75  \n",
              "3      0.333333        0.75         1.0           0.00  \n",
              "4      0.666667        0.75         1.0           0.75  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rryX7ZNWKCM",
        "outputId": "e6158a70-38d2-49b8-bd19-e17fd53357d4"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.247694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12.109011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12.317167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.849398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12.429216</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SalePrice\n",
              "0  12.247694\n",
              "1  12.109011\n",
              "2  12.317167\n",
              "3  11.849398\n",
              "4  12.429216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9a_wITeWKCO"
      },
      "source": [
        "## splitting the data for training and testing purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U7xYWc6WKCO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train.values, y_train.values,test_size = 0.25, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJpnkSd8afMd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg0acp-XWKCS"
      },
      "source": [
        "## Predicting and selecting the algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw1jQZjBWKCS"
      },
      "source": [
        "#import xgboost\n",
        "#classifier=xgboost.XGBRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9xmavuMWKCU"
      },
      "source": [
        "import xgboost\n",
        "regressor=xgboost.XGBRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMNZfIVcWKCX"
      },
      "source": [
        "booster=['gbtree','gblinear']\n",
        "base_score=[0.25,0.5,0.75,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf2lIIa_WKCY"
      },
      "source": [
        "## Hyper Parameter Optimization\n",
        "\n",
        "\n",
        "n_estimators = [100, 500, 900, 1100, 1500]\n",
        "max_depth = [2, 3, 5, 10, 15]\n",
        "booster=['gbtree','gblinear']\n",
        "learning_rate=[0.05,0.1,0.15,0.20]\n",
        "min_child_weight=[1,2,3,4]\n",
        "\n",
        "# Define the grid of hyperparameters to search\n",
        "hyperparameter_grid = {\n",
        "    'n_estimators': n_estimators,\n",
        "    'max_depth':max_depth,\n",
        "    'learning_rate':learning_rate,\n",
        "    'min_child_weight':min_child_weight,\n",
        "    'booster':booster,\n",
        "    'base_score':base_score\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St-T9XHxWKCc"
      },
      "source": [
        "# Set up the random search with 4-fold cross validation\n",
        "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
        "random_cv = RandomizedSearchCV(estimator=regressor,\n",
        "            param_distributions=hyperparameter_grid,\n",
        "            cv=5, n_iter=50,\n",
        "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
        "            verbose = 5, \n",
        "            return_train_score = True,\n",
        "            random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9HE12w2WKCe",
        "outputId": "b1b5b6e5-e562-4896-d695-bac97ada8a3a"
      },
      "source": [
        "random_cv.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   15.7s\n",
            "[Parallel(n_jobs=4)]: Done 180 tasks      | elapsed:   27.2s\n",
            "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:   33.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14:12:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
              "                                          colsample_bylevel=1,\n",
              "                                          colsample_bynode=1,\n",
              "                                          colsample_bytree=1, gamma=0,\n",
              "                                          importance_type='gain',\n",
              "                                          learning_rate=0.1, max_delta_step=0,\n",
              "                                          max_depth=3, min_child_weight=1,\n",
              "                                          missing=None, n_estimators=100,\n",
              "                                          n_jobs=1, nthread=None,\n",
              "                                          objective='reg:linear',\n",
              "                                          random_state=0, reg_alpha=...\n",
              "                   iid='deprecated', n_iter=50, n_jobs=4,\n",
              "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
              "                                        'booster': ['gbtree', 'gblinear'],\n",
              "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
              "                                        'max_depth': [2, 3, 5, 10, 15],\n",
              "                                        'min_child_weight': [1, 2, 3, 4],\n",
              "                                        'n_estimators': [100, 500, 900, 1100,\n",
              "                                                         1500]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "                   verbose=5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzXd22zqWKCg",
        "outputId": "95ee00dc-d245-4d50-eb43-31814048ee29"
      },
      "source": [
        "random_cv.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.05, max_delta_step=0,\n",
              "             max_depth=2, min_child_weight=4, missing=None, n_estimators=900,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIYRBgQGWKCj"
      },
      "source": [
        "regressor = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
        "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
        "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
        "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
        "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "       silent=True, subsample=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpB8hP1XWKCl",
        "outputId": "55a75b20-1deb-499d-d88a-f8d867acddb7"
      },
      "source": [
        "regressor.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=True, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JazcsjNWKCo",
        "outputId": "1c2c939b-1c40-485b-ba64-6c26f5de1f6b"
      },
      "source": [
        "# XGBoost\n",
        "y_predB = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_predB.reshape(len(y_predB),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11.82 11.95]\n",
            " [12.73 12.69]\n",
            " [11.59 11.65]\n",
            " [11.99 11.98]\n",
            " [12.73 12.66]\n",
            " [11.31 11.23]\n",
            " [12.4  12.65]\n",
            " [11.93 11.89]\n",
            " [11.28 11.34]\n",
            " [11.67 11.82]\n",
            " [11.81 11.88]\n",
            " [11.71 11.78]\n",
            " [11.39 11.3 ]\n",
            " [12.27 12.27]\n",
            " [12.07 12.11]\n",
            " [11.84 11.81]\n",
            " [12.19 12.12]\n",
            " [11.79 11.81]\n",
            " [11.65 11.68]\n",
            " [12.24 12.33]\n",
            " [12.13 11.95]\n",
            " [12.27 12.25]\n",
            " [12.08 12.06]\n",
            " [11.86 11.77]\n",
            " [12.25 12.17]\n",
            " [11.96 11.94]\n",
            " [12.18 12.11]\n",
            " [11.56 11.86]\n",
            " [12.11 12.11]\n",
            " [12.24 12.25]\n",
            " [11.77 11.75]\n",
            " [12.44 12.56]\n",
            " [12.43 12.21]\n",
            " [11.67 11.82]\n",
            " [12.5  12.45]\n",
            " [11.92 11.85]\n",
            " [11.89 11.84]\n",
            " [12.32 12.3 ]\n",
            " [12.65 12.64]\n",
            " [11.42 11.48]\n",
            " [11.8  11.65]\n",
            " [12.47 12.23]\n",
            " [11.76 11.69]\n",
            " [12.8  12.44]\n",
            " [11.79 11.76]\n",
            " [11.79 11.67]\n",
            " [11.61 11.65]\n",
            " [11.78 11.75]\n",
            " [13.03 13.02]\n",
            " [11.82 11.88]\n",
            " [11.7  11.69]\n",
            " [12.19 12.19]\n",
            " [11.6  11.65]\n",
            " [12.72 12.57]\n",
            " [11.9  11.88]\n",
            " [12.38 12.47]\n",
            " [12.15 12.27]\n",
            " [12.   12.07]\n",
            " [11.83 11.58]\n",
            " [11.5  11.59]\n",
            " [11.02 11.13]\n",
            " [11.95 11.94]\n",
            " [12.65 12.67]\n",
            " [12.49 12.48]\n",
            " [12.65 12.55]\n",
            " [12.29 12.4 ]\n",
            " [11.66 11.6 ]\n",
            " [12.77 12.63]\n",
            " [11.58 11.45]\n",
            " [11.96 12.08]\n",
            " [11.76 11.69]\n",
            " [11.82 11.81]\n",
            " [11.63 11.6 ]\n",
            " [11.41 11.45]\n",
            " [13.13 13.32]\n",
            " [12.12 12.06]\n",
            " [12.61 12.76]\n",
            " [12.66 12.74]\n",
            " [11.88 11.86]\n",
            " [11.71 11.74]\n",
            " [11.53 11.68]\n",
            " [11.42 11.11]\n",
            " [11.77 11.64]\n",
            " [11.49 11.42]\n",
            " [11.9  11.92]\n",
            " [11.86 11.8 ]\n",
            " [12.49 12.49]\n",
            " [12.22 12.15]\n",
            " [11.87 11.96]\n",
            " [12.09 11.96]\n",
            " [11.84 11.94]\n",
            " [12.02 11.93]\n",
            " [11.73 11.73]\n",
            " [12.6  12.61]\n",
            " [11.69 11.82]\n",
            " [12.15 12.04]\n",
            " [12.05 12.23]\n",
            " [12.08 12.12]\n",
            " [12.24 12.23]\n",
            " [12.39 12.47]\n",
            " [11.98 12.  ]\n",
            " [12.25 12.32]\n",
            " [12.26 12.4 ]\n",
            " [11.72 11.79]\n",
            " [12.15 12.18]\n",
            " [12.01 11.96]\n",
            " [11.93 11.96]\n",
            " [12.54 12.52]\n",
            " [11.86 11.88]\n",
            " [12.09 11.81]\n",
            " [10.7  11.  ]\n",
            " [11.67 11.73]\n",
            " [11.76 11.75]\n",
            " [11.88 11.83]\n",
            " [12.21 12.27]\n",
            " [11.61 11.69]\n",
            " [11.58 11.59]\n",
            " [11.86 11.72]\n",
            " [11.77 11.63]\n",
            " [12.48 12.56]\n",
            " [11.81 11.8 ]\n",
            " [11.86 11.91]\n",
            " [12.11 12.04]\n",
            " [12.04 12.24]\n",
            " [11.91 12.07]\n",
            " [11.76 11.83]\n",
            " [12.36 12.37]\n",
            " [11.65 11.28]\n",
            " [11.88 11.88]\n",
            " [12.09 12.  ]\n",
            " [12.15 12.13]\n",
            " [12.92 12.82]\n",
            " [12.21 12.2 ]\n",
            " [11.59 11.55]\n",
            " [10.87 10.47]\n",
            " [12.81 12.73]\n",
            " [12.71 12.81]\n",
            " [11.83 11.78]\n",
            " [12.27 12.35]\n",
            " [13.47 13.53]\n",
            " [12.87 12.91]\n",
            " [11.73 11.79]\n",
            " [12.06 12.09]\n",
            " [11.91 11.82]\n",
            " [11.8  11.88]\n",
            " [11.76 11.72]\n",
            " [12.24 12.43]\n",
            " [12.19 12.14]\n",
            " [11.72 11.8 ]\n",
            " [10.97 11.11]\n",
            " [11.79 11.83]\n",
            " [11.86 11.95]\n",
            " [12.37 12.21]\n",
            " [11.85 11.95]\n",
            " [11.38 11.42]\n",
            " [11.74 11.82]\n",
            " [11.99 11.6 ]\n",
            " [11.9  11.85]\n",
            " [11.39 11.36]\n",
            " [11.89 11.79]\n",
            " [12.22 12.1 ]\n",
            " [11.92 11.88]\n",
            " [12.62 12.59]\n",
            " [11.97 11.88]\n",
            " [11.7  11.68]\n",
            " [11.64 11.86]\n",
            " [12.31 12.38]\n",
            " [12.69 12.53]\n",
            " [13.04 13.23]\n",
            " [12.37 12.41]\n",
            " [12.9  12.79]\n",
            " [11.38 11.54]\n",
            " [11.68 11.53]\n",
            " [11.99 11.93]\n",
            " [12.82 12.56]\n",
            " [11.92 11.81]\n",
            " [11.82 11.64]\n",
            " [12.27 12.14]\n",
            " [11.81 11.74]\n",
            " [12.08 12.09]\n",
            " [11.99 12.1 ]\n",
            " [11.38 10.93]\n",
            " [11.83 11.79]\n",
            " [11.86 11.81]\n",
            " [12.44 12.45]\n",
            " [11.82 11.85]\n",
            " [12.41 12.51]\n",
            " [12.32 12.42]\n",
            " [12.21 12.22]\n",
            " [11.28 11.23]\n",
            " [11.75 11.72]\n",
            " [11.59 11.59]\n",
            " [11.79 11.98]\n",
            " [11.91 12.05]\n",
            " [12.15 12.19]\n",
            " [12.14 12.32]\n",
            " [12.29 12.19]\n",
            " [11.28 10.6 ]\n",
            " [12.23 12.06]\n",
            " [11.91 11.95]\n",
            " [12.32 12.54]\n",
            " [12.1  12.07]\n",
            " [11.76 11.9 ]\n",
            " [12.73 12.66]\n",
            " [12.21 12.13]\n",
            " [11.76 11.82]\n",
            " [12.4  12.39]\n",
            " [11.84 11.84]\n",
            " [11.99 11.85]\n",
            " [11.65 11.61]\n",
            " [12.41 12.32]\n",
            " [11.91 11.87]\n",
            " [11.7  11.77]\n",
            " [11.95 12.06]\n",
            " [12.33 12.39]\n",
            " [12.52 12.48]\n",
            " [12.19 12.18]\n",
            " [11.88 11.87]\n",
            " [11.92 11.78]\n",
            " [11.76 11.74]\n",
            " [11.8  11.87]\n",
            " [12.29 12.45]\n",
            " [12.24 12.29]\n",
            " [11.49 11.1 ]\n",
            " [12.34 12.21]\n",
            " [11.85 11.95]\n",
            " [11.43 11.13]\n",
            " [11.48 11.07]\n",
            " [12.05 12.06]\n",
            " [11.36 11.54]\n",
            " [11.49 11.35]\n",
            " [12.09 12.02]\n",
            " [11.7  11.7 ]\n",
            " [11.72 11.81]\n",
            " [12.35 12.3 ]\n",
            " [11.83 11.94]\n",
            " [12.19 12.18]\n",
            " [11.97 11.9 ]\n",
            " [12.39 12.53]\n",
            " [11.67 11.87]\n",
            " [11.45 11.57]\n",
            " [12.5  12.4 ]\n",
            " [12.18 12.18]\n",
            " [13.03 12.99]\n",
            " [12.13 12.13]\n",
            " [11.79 11.59]\n",
            " [12.01 12.01]\n",
            " [12.09 12.08]\n",
            " [11.77 11.77]\n",
            " [11.51 11.65]\n",
            " [12.14 12.17]\n",
            " [12.08 11.98]\n",
            " [11.82 11.88]\n",
            " [11.37 11.36]\n",
            " [11.79 11.97]\n",
            " [11.87 11.76]\n",
            " [11.66 11.65]\n",
            " [11.55 11.69]\n",
            " [12.11 12.08]\n",
            " [12.49 12.39]\n",
            " [12.62 12.89]\n",
            " [12.05 12.01]\n",
            " [11.76 11.76]\n",
            " [12.3  12.52]\n",
            " [12.59 12.65]\n",
            " [12.35 12.27]\n",
            " [12.06 11.94]\n",
            " [11.84 11.88]\n",
            " [11.67 11.65]\n",
            " [12.06 12.1 ]\n",
            " [12.99 13.05]\n",
            " [12.26 12.1 ]\n",
            " [12.4  12.44]\n",
            " [11.48 11.35]\n",
            " [11.55 11.53]\n",
            " [11.79 11.91]\n",
            " [11.83 11.83]\n",
            " [12.6  12.67]\n",
            " [12.42 11.87]\n",
            " [11.85 11.85]\n",
            " [12.21 12.17]\n",
            " [11.53 11.43]\n",
            " [12.28 12.19]\n",
            " [11.49 11.6 ]\n",
            " [12.64 12.6 ]\n",
            " [12.08 12.13]\n",
            " [12.25 12.35]\n",
            " [11.59 11.4 ]\n",
            " [12.42 12.47]\n",
            " [12.14 12.15]\n",
            " [11.73 11.59]\n",
            " [11.65 11.73]\n",
            " [11.84 11.88]\n",
            " [12.09 12.09]\n",
            " [11.28 11.35]\n",
            " [11.88 12.07]\n",
            " [11.78 11.75]\n",
            " [11.7  11.92]\n",
            " [12.12 12.07]\n",
            " [11.71 11.74]\n",
            " [12.06 12.08]\n",
            " [12.39 12.32]\n",
            " [11.79 11.77]\n",
            " [11.92 11.98]\n",
            " [12.04 11.96]\n",
            " [12.15 12.23]\n",
            " [11.96 11.85]\n",
            " [12.33 12.21]\n",
            " [12.39 12.29]\n",
            " [11.71 11.74]\n",
            " [11.89 11.98]\n",
            " [12.22 12.12]\n",
            " [11.5  11.48]\n",
            " [12.23 12.21]\n",
            " [11.83 11.91]\n",
            " [12.13 12.09]\n",
            " [12.12 12.13]\n",
            " [12.01 12.01]\n",
            " [12.59 12.72]\n",
            " [11.43 11.38]\n",
            " [12.31 12.36]\n",
            " [11.81 11.91]\n",
            " [11.68 11.8 ]\n",
            " [11.36 11.49]\n",
            " [12.09 12.24]\n",
            " [11.99 11.92]\n",
            " [11.77 11.81]\n",
            " [12.31 12.14]\n",
            " [12.   11.92]\n",
            " [11.5  11.66]\n",
            " [12.13 11.94]\n",
            " [11.86 12.01]\n",
            " [11.7  11.78]\n",
            " [12.5  12.24]\n",
            " [11.92 11.89]\n",
            " [11.79 11.75]\n",
            " [11.91 11.84]\n",
            " [11.53 11.64]\n",
            " [11.26 11.28]\n",
            " [12.3  12.11]\n",
            " [12.11 12.14]\n",
            " [11.83 11.77]\n",
            " [11.89 11.98]\n",
            " [12.05 12.07]\n",
            " [12.33 12.3 ]\n",
            " [12.67 12.64]\n",
            " [12.57 12.83]\n",
            " [11.55 11.51]\n",
            " [12.43 12.43]\n",
            " [11.73 11.88]\n",
            " [12.45 12.69]\n",
            " [12.88 12.85]\n",
            " [12.59 12.52]\n",
            " [12.05 12.1 ]\n",
            " [12.37 12.41]\n",
            " [11.84 11.93]\n",
            " [11.75 11.81]\n",
            " [11.53 11.45]\n",
            " [12.29 12.28]\n",
            " [12.85 12.77]\n",
            " [12.19 12.18]\n",
            " [11.79 11.7 ]\n",
            " [12.5  12.34]\n",
            " [12.15 12.42]\n",
            " [11.77 11.73]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRuMgxjbWKCq",
        "outputId": "aff08f11-be65-4ede-caa2-48b41f3f483d"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "print('The accuracy is {:.0%}'.format(r2_score(y_test, y_predB)))\n",
        "print('The mean squared error is {:.0%}'.format(mean_squared_error(y_test, y_predB)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is 91%\n",
            "The mean squared error is 2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt5JgPYyWKCs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBP-RH-dWKCu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa-ssU1XWKCx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldDKzz-NWKC0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz89P_uvWKC2",
        "outputId": "82e1f158-bb56-4f43-d3c3-313b31fb5727"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c443T1mZWKC4",
        "outputId": "d0e43744-c112-498c-85d9-9996afd146e4"
      },
      "source": [
        "# Multiple Linear Regression\n",
        "y_predM = Lregressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_predM.reshape(len(y_predM),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11.78 11.95]\n",
            " [12.72 12.69]\n",
            " [11.66 11.65]\n",
            " [11.92 11.98]\n",
            " [12.73 12.66]\n",
            " [11.25 11.23]\n",
            " [12.31 12.65]\n",
            " [11.91 11.89]\n",
            " [11.24 11.34]\n",
            " [11.71 11.82]\n",
            " [11.91 11.88]\n",
            " [11.68 11.78]\n",
            " [11.42 11.3 ]\n",
            " [12.27 12.27]\n",
            " [12.06 12.11]\n",
            " [11.81 11.81]\n",
            " [12.23 12.12]\n",
            " [11.75 11.81]\n",
            " [11.61 11.68]\n",
            " [12.3  12.33]\n",
            " [12.12 11.95]\n",
            " [12.28 12.25]\n",
            " [12.14 12.06]\n",
            " [11.76 11.77]\n",
            " [12.28 12.17]\n",
            " [11.91 11.94]\n",
            " [12.21 12.11]\n",
            " [11.63 11.86]\n",
            " [12.11 12.11]\n",
            " [12.24 12.25]\n",
            " [11.73 11.75]\n",
            " [12.51 12.56]\n",
            " [12.24 12.21]\n",
            " [11.57 11.82]\n",
            " [12.5  12.45]\n",
            " [11.89 11.85]\n",
            " [11.98 11.84]\n",
            " [12.29 12.3 ]\n",
            " [12.59 12.64]\n",
            " [11.42 11.48]\n",
            " [11.73 11.65]\n",
            " [12.36 12.23]\n",
            " [11.62 11.69]\n",
            " [12.66 12.44]\n",
            " [11.75 11.76]\n",
            " [11.85 11.67]\n",
            " [11.55 11.65]\n",
            " [11.7  11.75]\n",
            " [12.89 13.02]\n",
            " [11.78 11.88]\n",
            " [11.63 11.69]\n",
            " [12.22 12.19]\n",
            " [11.65 11.65]\n",
            " [12.66 12.57]\n",
            " [11.97 11.88]\n",
            " [12.38 12.47]\n",
            " [12.26 12.27]\n",
            " [11.89 12.07]\n",
            " [11.83 11.58]\n",
            " [11.55 11.59]\n",
            " [11.05 11.13]\n",
            " [11.92 11.94]\n",
            " [12.66 12.67]\n",
            " [12.46 12.48]\n",
            " [12.68 12.55]\n",
            " [12.3  12.4 ]\n",
            " [11.57 11.6 ]\n",
            " [12.72 12.63]\n",
            " [11.59 11.45]\n",
            " [12.02 12.08]\n",
            " [11.75 11.69]\n",
            " [11.8  11.81]\n",
            " [11.57 11.6 ]\n",
            " [11.36 11.45]\n",
            " [12.95 13.32]\n",
            " [12.15 12.06]\n",
            " [12.64 12.76]\n",
            " [12.67 12.74]\n",
            " [11.8  11.86]\n",
            " [11.67 11.74]\n",
            " [11.54 11.68]\n",
            " [11.42 11.11]\n",
            " [11.72 11.64]\n",
            " [11.52 11.42]\n",
            " [11.91 11.92]\n",
            " [11.73 11.8 ]\n",
            " [12.51 12.49]\n",
            " [12.23 12.15]\n",
            " [11.91 11.96]\n",
            " [12.19 11.96]\n",
            " [11.89 11.94]\n",
            " [11.94 11.93]\n",
            " [11.67 11.73]\n",
            " [12.5  12.61]\n",
            " [11.61 11.82]\n",
            " [12.14 12.04]\n",
            " [11.93 12.23]\n",
            " [12.16 12.12]\n",
            " [12.24 12.23]\n",
            " [12.39 12.47]\n",
            " [12.07 12.  ]\n",
            " [12.27 12.32]\n",
            " [12.46 12.4 ]\n",
            " [11.69 11.79]\n",
            " [12.13 12.18]\n",
            " [12.1  11.96]\n",
            " [11.91 11.96]\n",
            " [12.44 12.52]\n",
            " [11.83 11.88]\n",
            " [12.07 11.81]\n",
            " [11.04 11.  ]\n",
            " [11.69 11.73]\n",
            " [11.77 11.75]\n",
            " [11.74 11.83]\n",
            " [12.26 12.27]\n",
            " [11.6  11.69]\n",
            " [11.51 11.59]\n",
            " [11.69 11.72]\n",
            " [11.85 11.63]\n",
            " [12.52 12.56]\n",
            " [11.78 11.8 ]\n",
            " [11.94 11.91]\n",
            " [12.14 12.04]\n",
            " [12.03 12.24]\n",
            " [12.24 12.07]\n",
            " [11.69 11.83]\n",
            " [12.34 12.37]\n",
            " [11.48 11.28]\n",
            " [11.88 11.88]\n",
            " [12.11 12.  ]\n",
            " [12.15 12.13]\n",
            " [12.77 12.82]\n",
            " [12.24 12.2 ]\n",
            " [11.76 11.55]\n",
            " [10.95 10.47]\n",
            " [12.82 12.73]\n",
            " [12.64 12.81]\n",
            " [11.85 11.78]\n",
            " [12.35 12.35]\n",
            " [13.12 13.53]\n",
            " [12.73 12.91]\n",
            " [11.7  11.79]\n",
            " [12.1  12.09]\n",
            " [11.96 11.82]\n",
            " [11.68 11.88]\n",
            " [11.7  11.72]\n",
            " [12.27 12.43]\n",
            " [12.17 12.14]\n",
            " [11.68 11.8 ]\n",
            " [11.28 11.11]\n",
            " [11.72 11.83]\n",
            " [11.87 11.95]\n",
            " [12.37 12.21]\n",
            " [11.96 11.95]\n",
            " [11.36 11.42]\n",
            " [11.78 11.82]\n",
            " [11.83 11.6 ]\n",
            " [11.97 11.85]\n",
            " [11.38 11.36]\n",
            " [11.86 11.79]\n",
            " [12.25 12.1 ]\n",
            " [11.84 11.88]\n",
            " [12.61 12.59]\n",
            " [11.97 11.88]\n",
            " [11.61 11.68]\n",
            " [11.7  11.86]\n",
            " [12.34 12.38]\n",
            " [12.63 12.53]\n",
            " [12.87 13.23]\n",
            " [12.27 12.41]\n",
            " [12.86 12.79]\n",
            " [11.41 11.54]\n",
            " [11.69 11.53]\n",
            " [11.98 11.93]\n",
            " [12.64 12.56]\n",
            " [11.83 11.81]\n",
            " [11.82 11.64]\n",
            " [12.31 12.14]\n",
            " [11.69 11.74]\n",
            " [12.05 12.09]\n",
            " [11.97 12.1 ]\n",
            " [11.44 10.93]\n",
            " [11.76 11.79]\n",
            " [11.86 11.81]\n",
            " [12.46 12.45]\n",
            " [11.89 11.85]\n",
            " [12.46 12.51]\n",
            " [12.39 12.42]\n",
            " [12.22 12.22]\n",
            " [11.38 11.23]\n",
            " [11.7  11.72]\n",
            " [11.59 11.59]\n",
            " [11.94 11.98]\n",
            " [11.88 12.05]\n",
            " [12.24 12.19]\n",
            " [12.09 12.32]\n",
            " [12.28 12.19]\n",
            " [11.37 10.6 ]\n",
            " [12.25 12.06]\n",
            " [11.86 11.95]\n",
            " [12.38 12.54]\n",
            " [12.18 12.07]\n",
            " [11.64 11.9 ]\n",
            " [12.67 12.66]\n",
            " [12.23 12.13]\n",
            " [11.68 11.82]\n",
            " [12.31 12.39]\n",
            " [11.78 11.84]\n",
            " [12.   11.85]\n",
            " [11.61 11.61]\n",
            " [12.4  12.32]\n",
            " [11.93 11.87]\n",
            " [11.64 11.77]\n",
            " [11.99 12.06]\n",
            " [12.36 12.39]\n",
            " [12.45 12.48]\n",
            " [12.31 12.18]\n",
            " [11.83 11.87]\n",
            " [11.89 11.78]\n",
            " [11.85 11.74]\n",
            " [11.76 11.87]\n",
            " [12.33 12.45]\n",
            " [12.25 12.29]\n",
            " [11.51 11.1 ]\n",
            " [12.4  12.21]\n",
            " [11.85 11.95]\n",
            " [11.43 11.13]\n",
            " [11.56 11.07]\n",
            " [12.05 12.06]\n",
            " [11.41 11.54]\n",
            " [11.46 11.35]\n",
            " [12.08 12.02]\n",
            " [11.7  11.7 ]\n",
            " [11.67 11.81]\n",
            " [12.31 12.3 ]\n",
            " [11.79 11.94]\n",
            " [12.19 12.18]\n",
            " [11.96 11.9 ]\n",
            " [12.38 12.53]\n",
            " [11.71 11.87]\n",
            " [11.57 11.57]\n",
            " [12.43 12.4 ]\n",
            " [12.16 12.18]\n",
            " [12.92 12.99]\n",
            " [12.12 12.13]\n",
            " [11.69 11.59]\n",
            " [11.98 12.01]\n",
            " [12.14 12.08]\n",
            " [11.7  11.77]\n",
            " [11.48 11.65]\n",
            " [12.16 12.17]\n",
            " [12.12 11.98]\n",
            " [11.8  11.88]\n",
            " [11.38 11.36]\n",
            " [11.75 11.97]\n",
            " [11.83 11.76]\n",
            " [11.68 11.65]\n",
            " [11.53 11.69]\n",
            " [12.05 12.08]\n",
            " [12.44 12.39]\n",
            " [12.63 12.89]\n",
            " [12.03 12.01]\n",
            " [11.79 11.76]\n",
            " [12.3  12.52]\n",
            " [12.57 12.65]\n",
            " [12.36 12.27]\n",
            " [12.   11.94]\n",
            " [11.89 11.88]\n",
            " [11.64 11.65]\n",
            " [12.1  12.1 ]\n",
            " [12.91 13.05]\n",
            " [12.27 12.1 ]\n",
            " [12.37 12.44]\n",
            " [11.49 11.35]\n",
            " [11.58 11.53]\n",
            " [11.76 11.91]\n",
            " [11.97 11.83]\n",
            " [12.55 12.67]\n",
            " [12.35 11.87]\n",
            " [11.9  11.85]\n",
            " [12.22 12.17]\n",
            " [11.31 11.43]\n",
            " [12.24 12.19]\n",
            " [11.56 11.6 ]\n",
            " [12.6  12.6 ]\n",
            " [12.09 12.13]\n",
            " [12.28 12.35]\n",
            " [11.58 11.4 ]\n",
            " [12.48 12.47]\n",
            " [12.29 12.15]\n",
            " [11.77 11.59]\n",
            " [11.6  11.73]\n",
            " [11.83 11.88]\n",
            " [12.07 12.09]\n",
            " [11.38 11.35]\n",
            " [12.03 12.07]\n",
            " [11.87 11.75]\n",
            " [11.73 11.92]\n",
            " [12.18 12.07]\n",
            " [11.61 11.74]\n",
            " [12.09 12.08]\n",
            " [12.37 12.32]\n",
            " [11.74 11.77]\n",
            " [11.87 11.98]\n",
            " [12.09 11.96]\n",
            " [12.18 12.23]\n",
            " [11.95 11.85]\n",
            " [12.28 12.21]\n",
            " [12.36 12.29]\n",
            " [11.63 11.74]\n",
            " [11.87 11.98]\n",
            " [12.27 12.12]\n",
            " [11.48 11.48]\n",
            " [12.21 12.21]\n",
            " [11.74 11.91]\n",
            " [12.14 12.09]\n",
            " [12.11 12.13]\n",
            " [12.05 12.01]\n",
            " [12.5  12.72]\n",
            " [11.34 11.38]\n",
            " [12.29 12.36]\n",
            " [11.81 11.91]\n",
            " [11.77 11.8 ]\n",
            " [11.42 11.49]\n",
            " [12.19 12.24]\n",
            " [12.   11.92]\n",
            " [11.74 11.81]\n",
            " [12.33 12.14]\n",
            " [12.08 11.92]\n",
            " [11.49 11.66]\n",
            " [12.   11.94]\n",
            " [11.93 12.01]\n",
            " [11.73 11.78]\n",
            " [12.24 12.24]\n",
            " [12.01 11.89]\n",
            " [11.73 11.75]\n",
            " [11.93 11.84]\n",
            " [11.49 11.64]\n",
            " [11.44 11.28]\n",
            " [12.26 12.11]\n",
            " [12.16 12.14]\n",
            " [11.78 11.77]\n",
            " [11.71 11.98]\n",
            " [12.08 12.07]\n",
            " [12.4  12.3 ]\n",
            " [12.78 12.64]\n",
            " [12.78 12.83]\n",
            " [11.61 11.51]\n",
            " [12.37 12.43]\n",
            " [11.69 11.88]\n",
            " [12.41 12.69]\n",
            " [12.8  12.85]\n",
            " [12.44 12.52]\n",
            " [12.09 12.1 ]\n",
            " [12.41 12.41]\n",
            " [11.77 11.93]\n",
            " [11.72 11.81]\n",
            " [11.44 11.45]\n",
            " [12.3  12.28]\n",
            " [12.73 12.77]\n",
            " [12.15 12.18]\n",
            " [11.78 11.7 ]\n",
            " [12.4  12.34]\n",
            " [12.35 12.42]\n",
            " [11.76 11.73]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORBtsqEYWKC6",
        "outputId": "230af89a-98a9-40d7-f6bc-788c5d94ab5e"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print('The accuracy is {:.0%}'.format(r2_score(y_test, y_predM)))\n",
        "print('The mean squared error is {:.0%}'.format(mean_squared_error(y_test, y_predM)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is 90%\n",
            "The mean squared error is 2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KDQCfCrWKC8",
        "outputId": "75905731-282f-4568-b9ea-e84281b4b6a7"
      },
      "source": [
        "plt.scatter(y_test,y_predM)\n",
        "plt.xlabel('Y Test')\n",
        "plt.ylabel('Predicted Y')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Predicted Y')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0doZI2vWKC-",
        "outputId": "acd9cb00-8b96-4628-d397-4af1b0e22dee"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "poly_reg = PolynomialFeatures(degree = 4)\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_poly, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7dp6iiQWKDA"
      },
      "source": [
        "y_predP = regressor.predict(poly_reg.transform(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zDgrsGIWKDC",
        "outputId": "b23d8294-9124-4cd0-f285-bbe19b1cd4a6"
      },
      "source": [
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_predP.reshape(len(y_predP),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.71e+05  1.19e+01]\n",
            " [-1.18e+04  1.27e+01]\n",
            " [-2.52e+04  1.17e+01]\n",
            " [ 2.75e+05  1.20e+01]\n",
            " [ 9.20e+03  1.27e+01]\n",
            " [-9.47e+05  1.12e+01]\n",
            " [ 1.51e+05  1.26e+01]\n",
            " [ 1.54e+04  1.19e+01]\n",
            " [-1.08e+04  1.13e+01]\n",
            " [-1.14e+05  1.18e+01]\n",
            " [-1.84e+03  1.19e+01]\n",
            " [ 2.63e+04  1.18e+01]\n",
            " [ 3.21e+05  1.13e+01]\n",
            " [-1.24e+05  1.23e+01]\n",
            " [-3.05e+05  1.21e+01]\n",
            " [ 7.47e+04  1.18e+01]\n",
            " [-1.50e+04  1.21e+01]\n",
            " [-2.09e+05  1.18e+01]\n",
            " [ 2.08e+05  1.17e+01]\n",
            " [ 2.30e+01  1.23e+01]\n",
            " [ 1.04e+05  1.20e+01]\n",
            " [ 2.20e+04  1.23e+01]\n",
            " [ 5.29e+03  1.21e+01]\n",
            " [ 8.64e+04  1.18e+01]\n",
            " [ 1.60e+04  1.22e+01]\n",
            " [ 3.84e+04  1.19e+01]\n",
            " [ 3.06e+03  1.21e+01]\n",
            " [ 8.16e+04  1.19e+01]\n",
            " [-1.94e+03  1.21e+01]\n",
            " [ 1.25e+04  1.22e+01]\n",
            " [ 7.65e+04  1.18e+01]\n",
            " [-1.42e+05  1.26e+01]\n",
            " [-2.93e+05  1.22e+01]\n",
            " [ 7.43e+04  1.18e+01]\n",
            " [ 1.63e+05  1.24e+01]\n",
            " [ 1.14e+05  1.18e+01]\n",
            " [ 3.72e+04  1.18e+01]\n",
            " [ 7.57e+03  1.23e+01]\n",
            " [-7.69e+04  1.26e+01]\n",
            " [ 3.94e+05  1.15e+01]\n",
            " [-5.65e+03  1.16e+01]\n",
            " [ 3.21e+04  1.22e+01]\n",
            " [-2.08e+03  1.17e+01]\n",
            " [ 3.01e+04  1.24e+01]\n",
            " [ 1.81e+03  1.18e+01]\n",
            " [-3.80e+05  1.17e+01]\n",
            " [-2.08e+04  1.17e+01]\n",
            " [ 1.64e+05  1.18e+01]\n",
            " [ 2.82e+05  1.30e+01]\n",
            " [-4.32e+04  1.19e+01]\n",
            " [ 7.37e+03  1.17e+01]\n",
            " [-5.02e+04  1.22e+01]\n",
            " [-1.51e+06  1.17e+01]\n",
            " [-1.49e+05  1.26e+01]\n",
            " [-4.62e+05  1.19e+01]\n",
            " [ 2.81e+04  1.25e+01]\n",
            " [ 3.17e+04  1.23e+01]\n",
            " [ 1.95e+06  1.21e+01]\n",
            " [ 9.58e+05  1.16e+01]\n",
            " [-3.57e+05  1.16e+01]\n",
            " [-3.52e+04  1.11e+01]\n",
            " [ 1.49e+05  1.19e+01]\n",
            " [-4.40e+04  1.27e+01]\n",
            " [ 3.73e+04  1.25e+01]\n",
            " [ 6.84e+04  1.26e+01]\n",
            " [ 4.31e+03  1.24e+01]\n",
            " [ 1.50e+04  1.16e+01]\n",
            " [-2.03e+05  1.26e+01]\n",
            " [ 9.76e+05  1.14e+01]\n",
            " [ 1.72e+02  1.21e+01]\n",
            " [ 1.17e+01  1.17e+01]\n",
            " [-2.35e+04  1.18e+01]\n",
            " [-1.46e+04  1.16e+01]\n",
            " [ 2.76e+05  1.14e+01]\n",
            " [-2.14e+04  1.33e+01]\n",
            " [ 1.55e+04  1.21e+01]\n",
            " [ 7.53e+04  1.28e+01]\n",
            " [-2.86e+05  1.27e+01]\n",
            " [-1.22e+04  1.19e+01]\n",
            " [ 3.98e+05  1.17e+01]\n",
            " [-1.36e+05  1.17e+01]\n",
            " [-5.75e+05  1.11e+01]\n",
            " [ 7.49e+05  1.16e+01]\n",
            " [-6.40e+05  1.14e+01]\n",
            " [ 1.26e+05  1.19e+01]\n",
            " [-2.03e+05  1.18e+01]\n",
            " [ 1.47e+05  1.25e+01]\n",
            " [-6.15e+05  1.22e+01]\n",
            " [ 1.26e+04  1.20e+01]\n",
            " [-9.12e+04  1.20e+01]\n",
            " [ 4.41e+04  1.19e+01]\n",
            " [ 4.58e+04  1.19e+01]\n",
            " [ 2.43e+05  1.17e+01]\n",
            " [ 1.70e+05  1.26e+01]\n",
            " [-3.06e+05  1.18e+01]\n",
            " [ 7.78e+04  1.20e+01]\n",
            " [-6.44e+05  1.22e+01]\n",
            " [-5.84e+04  1.21e+01]\n",
            " [-1.06e+05  1.22e+01]\n",
            " [-1.83e+04  1.25e+01]\n",
            " [-8.29e+03  1.20e+01]\n",
            " [ 2.06e+03  1.23e+01]\n",
            " [-2.17e+04  1.24e+01]\n",
            " [-6.17e+04  1.18e+01]\n",
            " [ 2.30e+05  1.22e+01]\n",
            " [ 3.67e+04  1.20e+01]\n",
            " [-1.30e+04  1.20e+01]\n",
            " [-1.05e+05  1.25e+01]\n",
            " [ 1.16e+05  1.19e+01]\n",
            " [-1.97e+04  1.18e+01]\n",
            " [-1.44e+05  1.10e+01]\n",
            " [-1.01e+04  1.17e+01]\n",
            " [-7.24e+03  1.18e+01]\n",
            " [ 3.15e+04  1.18e+01]\n",
            " [-8.10e+03  1.23e+01]\n",
            " [-4.98e+06  1.17e+01]\n",
            " [ 5.76e+04  1.16e+01]\n",
            " [-2.45e+05  1.17e+01]\n",
            " [ 7.17e+05  1.16e+01]\n",
            " [ 1.20e+05  1.26e+01]\n",
            " [ 5.07e+04  1.18e+01]\n",
            " [-8.68e+04  1.19e+01]\n",
            " [-8.99e+04  1.20e+01]\n",
            " [-2.15e+05  1.22e+01]\n",
            " [-1.20e+05  1.21e+01]\n",
            " [-1.19e+04  1.18e+01]\n",
            " [-3.86e+03  1.24e+01]\n",
            " [ 2.50e+05  1.13e+01]\n",
            " [ 1.71e+05  1.19e+01]\n",
            " [ 4.40e+04  1.20e+01]\n",
            " [ 5.49e+02  1.21e+01]\n",
            " [-1.57e+05  1.28e+01]\n",
            " [-5.03e+04  1.22e+01]\n",
            " [ 4.11e+05  1.16e+01]\n",
            " [-1.24e+06  1.05e+01]\n",
            " [-1.34e+05  1.27e+01]\n",
            " [ 9.71e+04  1.28e+01]\n",
            " [-2.88e+05  1.18e+01]\n",
            " [ 2.81e+05  1.23e+01]\n",
            " [-2.43e+05  1.35e+01]\n",
            " [-1.41e+05  1.29e+01]\n",
            " [ 1.29e+05  1.18e+01]\n",
            " [ 6.38e+02  1.21e+01]\n",
            " [-8.36e+04  1.18e+01]\n",
            " [ 1.08e+06  1.19e+01]\n",
            " [-2.70e+05  1.17e+01]\n",
            " [ 2.42e+05  1.24e+01]\n",
            " [ 5.63e+01  1.21e+01]\n",
            " [-3.27e+04  1.18e+01]\n",
            " [ 1.03e+06  1.11e+01]\n",
            " [ 9.22e+04  1.18e+01]\n",
            " [ 1.47e+05  1.20e+01]\n",
            " [-5.08e+05  1.22e+01]\n",
            " [-7.06e+04  1.19e+01]\n",
            " [ 2.94e+05  1.14e+01]\n",
            " [ 1.52e+05  1.18e+01]\n",
            " [ 6.82e+05  1.16e+01]\n",
            " [ 2.33e+04  1.18e+01]\n",
            " [ 2.63e+04  1.14e+01]\n",
            " [-8.87e+04  1.18e+01]\n",
            " [-2.79e+04  1.21e+01]\n",
            " [ 2.40e+04  1.19e+01]\n",
            " [ 4.13e+04  1.26e+01]\n",
            " [-2.87e+03  1.19e+01]\n",
            " [-2.28e+04  1.17e+01]\n",
            " [ 1.83e+06  1.19e+01]\n",
            " [ 1.78e+04  1.24e+01]\n",
            " [-2.09e+05  1.25e+01]\n",
            " [ 1.00e+05  1.32e+01]\n",
            " [ 2.25e+05  1.24e+01]\n",
            " [-1.45e+05  1.28e+01]\n",
            " [-1.83e+05  1.15e+01]\n",
            " [ 6.47e+05  1.15e+01]\n",
            " [ 3.93e+05  1.19e+01]\n",
            " [-2.86e+05  1.26e+01]\n",
            " [ 2.44e+05  1.18e+01]\n",
            " [-2.74e+04  1.16e+01]\n",
            " [ 1.74e+04  1.21e+01]\n",
            " [-2.76e+05  1.17e+01]\n",
            " [ 8.53e+04  1.21e+01]\n",
            " [ 2.99e+05  1.21e+01]\n",
            " [ 8.12e+05  1.09e+01]\n",
            " [ 1.95e+05  1.18e+01]\n",
            " [ 2.56e+05  1.18e+01]\n",
            " [ 6.19e+04  1.24e+01]\n",
            " [-1.94e+05  1.18e+01]\n",
            " [ 1.35e+05  1.25e+01]\n",
            " [-1.61e+05  1.24e+01]\n",
            " [ 1.22e+01  1.22e+01]\n",
            " [-5.18e+05  1.12e+01]\n",
            " [-3.10e+05  1.17e+01]\n",
            " [ 7.01e+05  1.16e+01]\n",
            " [-6.64e+03  1.20e+01]\n",
            " [-4.26e+05  1.20e+01]\n",
            " [-5.12e+04  1.22e+01]\n",
            " [ 7.86e+05  1.23e+01]\n",
            " [ 3.05e+05  1.22e+01]\n",
            " [ 9.99e+04  1.06e+01]\n",
            " [ 8.04e+05  1.21e+01]\n",
            " [-1.08e+05  1.20e+01]\n",
            " [ 1.81e+05  1.25e+01]\n",
            " [-4.45e+04  1.21e+01]\n",
            " [ 1.42e+05  1.19e+01]\n",
            " [-2.28e+05  1.27e+01]\n",
            " [-9.15e+03  1.21e+01]\n",
            " [ 9.02e+04  1.18e+01]\n",
            " [-1.91e+03  1.24e+01]\n",
            " [ 3.81e+03  1.18e+01]\n",
            " [-1.02e+05  1.18e+01]\n",
            " [ 1.15e+01  1.16e+01]\n",
            " [-8.49e+04  1.23e+01]\n",
            " [ 1.10e+05  1.19e+01]\n",
            " [-1.27e+05  1.18e+01]\n",
            " [ 4.70e+04  1.21e+01]\n",
            " [-2.65e+05  1.24e+01]\n",
            " [-8.96e+04  1.25e+01]\n",
            " [ 6.11e+03  1.22e+01]\n",
            " [-2.46e+05  1.19e+01]\n",
            " [ 1.31e+06  1.18e+01]\n",
            " [ 4.23e+05  1.17e+01]\n",
            " [ 2.05e+04  1.19e+01]\n",
            " [-1.08e+05  1.24e+01]\n",
            " [ 4.92e+04  1.23e+01]\n",
            " [-6.31e+05  1.11e+01]\n",
            " [ 4.65e+03  1.22e+01]\n",
            " [ 2.13e+05  1.20e+01]\n",
            " [-1.81e+06  1.11e+01]\n",
            " [ 6.61e+04  1.11e+01]\n",
            " [-4.86e+05  1.21e+01]\n",
            " [-1.33e+06  1.15e+01]\n",
            " [ 2.25e+05  1.13e+01]\n",
            " [ 2.86e+04  1.20e+01]\n",
            " [ 9.89e+05  1.17e+01]\n",
            " [ 2.33e+04  1.18e+01]\n",
            " [ 3.41e+05  1.23e+01]\n",
            " [ 6.05e+02  1.19e+01]\n",
            " [ 1.06e+04  1.22e+01]\n",
            " [-1.79e+04  1.19e+01]\n",
            " [-3.92e+04  1.25e+01]\n",
            " [-1.19e+05  1.19e+01]\n",
            " [-1.51e+04  1.16e+01]\n",
            " [-2.39e+05  1.24e+01]\n",
            " [ 2.81e+04  1.22e+01]\n",
            " [-1.18e+05  1.30e+01]\n",
            " [-3.60e+05  1.21e+01]\n",
            " [ 1.65e+06  1.16e+01]\n",
            " [-2.74e+05  1.20e+01]\n",
            " [-1.13e+05  1.21e+01]\n",
            " [-2.31e+05  1.18e+01]\n",
            " [ 1.11e+04  1.17e+01]\n",
            " [-1.28e+05  1.22e+01]\n",
            " [-2.21e+04  1.20e+01]\n",
            " [-3.83e+05  1.19e+01]\n",
            " [ 9.19e+05  1.14e+01]\n",
            " [ 4.38e+04  1.20e+01]\n",
            " [-4.73e+04  1.18e+01]\n",
            " [ 9.32e+04  1.17e+01]\n",
            " [-3.73e+04  1.17e+01]\n",
            " [ 1.32e+03  1.21e+01]\n",
            " [ 3.77e+04  1.24e+01]\n",
            " [-3.36e+05  1.29e+01]\n",
            " [-5.08e+04  1.20e+01]\n",
            " [ 8.54e+04  1.18e+01]\n",
            " [-1.91e+04  1.25e+01]\n",
            " [ 1.67e+05  1.27e+01]\n",
            " [-3.95e+05  1.23e+01]\n",
            " [-7.03e+03  1.19e+01]\n",
            " [ 1.18e+01  1.19e+01]\n",
            " [ 2.59e+05  1.17e+01]\n",
            " [ 2.31e+04  1.21e+01]\n",
            " [ 7.87e+04  1.30e+01]\n",
            " [-9.35e+04  1.21e+01]\n",
            " [ 2.43e+03  1.24e+01]\n",
            " [-1.60e+05  1.14e+01]\n",
            " [-1.41e+04  1.15e+01]\n",
            " [-1.89e+03  1.19e+01]\n",
            " [ 1.18e+01  1.18e+01]\n",
            " [ 4.14e+05  1.27e+01]\n",
            " [-7.99e+04  1.19e+01]\n",
            " [ 6.63e+03  1.18e+01]\n",
            " [ 1.02e+05  1.22e+01]\n",
            " [ 2.75e+06  1.14e+01]\n",
            " [-1.96e+04  1.22e+01]\n",
            " [-8.71e+04  1.16e+01]\n",
            " [ 9.03e+03  1.26e+01]\n",
            " [-4.80e+01  1.21e+01]\n",
            " [-1.03e+02  1.23e+01]\n",
            " [-2.00e+05  1.14e+01]\n",
            " [-7.94e+04  1.25e+01]\n",
            " [-3.92e+04  1.21e+01]\n",
            " [ 1.68e+04  1.16e+01]\n",
            " [-8.69e+03  1.17e+01]\n",
            " [-4.30e+04  1.19e+01]\n",
            " [-8.37e+03  1.21e+01]\n",
            " [ 3.38e+05  1.14e+01]\n",
            " [ 2.18e+05  1.21e+01]\n",
            " [-2.07e+05  1.18e+01]\n",
            " [-1.22e+06  1.19e+01]\n",
            " [-4.46e+04  1.21e+01]\n",
            " [-1.51e+05  1.17e+01]\n",
            " [ 1.12e+05  1.21e+01]\n",
            " [ 7.88e+04  1.23e+01]\n",
            " [ 4.06e+04  1.18e+01]\n",
            " [-1.07e+05  1.20e+01]\n",
            " [ 2.11e+05  1.20e+01]\n",
            " [-5.19e+05  1.22e+01]\n",
            " [-5.36e+04  1.18e+01]\n",
            " [-5.28e+04  1.22e+01]\n",
            " [-1.40e+06  1.23e+01]\n",
            " [ 3.23e+04  1.17e+01]\n",
            " [-3.19e+04  1.20e+01]\n",
            " [ 8.54e+03  1.21e+01]\n",
            " [ 3.71e+05  1.15e+01]\n",
            " [-1.43e+05  1.22e+01]\n",
            " [ 2.13e+05  1.19e+01]\n",
            " [ 7.67e+02  1.21e+01]\n",
            " [ 3.31e+04  1.21e+01]\n",
            " [ 6.46e+05  1.20e+01]\n",
            " [ 1.72e+05  1.27e+01]\n",
            " [-7.16e+04  1.14e+01]\n",
            " [-9.33e+04  1.24e+01]\n",
            " [ 9.91e+04  1.19e+01]\n",
            " [-7.06e+03  1.18e+01]\n",
            " [ 1.09e+06  1.15e+01]\n",
            " [-1.45e+04  1.22e+01]\n",
            " [ 5.86e+04  1.19e+01]\n",
            " [-1.25e+05  1.18e+01]\n",
            " [ 8.10e+04  1.21e+01]\n",
            " [ 9.12e+04  1.19e+01]\n",
            " [-9.36e+05  1.17e+01]\n",
            " [ 6.97e+05  1.19e+01]\n",
            " [ 1.99e+05  1.20e+01]\n",
            " [ 1.14e+04  1.18e+01]\n",
            " [-2.08e+06  1.22e+01]\n",
            " [-6.63e+05  1.19e+01]\n",
            " [-7.04e+04  1.17e+01]\n",
            " [ 1.04e+05  1.18e+01]\n",
            " [-4.36e+05  1.16e+01]\n",
            " [ 1.50e+06  1.13e+01]\n",
            " [-1.31e+05  1.21e+01]\n",
            " [-1.24e+04  1.21e+01]\n",
            " [ 6.82e+03  1.18e+01]\n",
            " [ 3.51e+05  1.20e+01]\n",
            " [-6.84e+05  1.21e+01]\n",
            " [-9.22e+04  1.23e+01]\n",
            " [-3.96e+05  1.26e+01]\n",
            " [-3.13e+03  1.28e+01]\n",
            " [-1.94e+05  1.15e+01]\n",
            " [ 1.22e+05  1.24e+01]\n",
            " [-5.34e+04  1.19e+01]\n",
            " [-1.35e+05  1.27e+01]\n",
            " [ 1.62e+05  1.28e+01]\n",
            " [ 5.01e+05  1.25e+01]\n",
            " [ 2.99e+04  1.21e+01]\n",
            " [ 1.40e+05  1.24e+01]\n",
            " [ 2.47e+05  1.19e+01]\n",
            " [ 1.38e+03  1.18e+01]\n",
            " [ 1.37e+06  1.15e+01]\n",
            " [-2.50e+04  1.23e+01]\n",
            " [-1.47e+04  1.28e+01]\n",
            " [ 2.40e+04  1.22e+01]\n",
            " [ 9.63e+04  1.17e+01]\n",
            " [-2.69e+04  1.23e+01]\n",
            " [ 2.67e+05  1.24e+01]\n",
            " [ 5.31e+03  1.17e+01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gzyY4MWKDE",
        "outputId": "bb0d174b-294b-45fa-f87e-cb0fdf431fb8"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print('The accuracy is {:.0%}'.format(r2_score(y_test, y_predP)))\n",
        "print('The mean squared error is {:.0%}'.format(mean_squared_error(y_test, y_predP)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is -143772830549897%\n",
            "The mean squared error is 24895618268385%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFK0hRnbWKDI",
        "outputId": "bbbcfdc3-1755-4d39-ad72-aa45368b79ed"
      },
      "source": [
        "plt.scatter(y_test,y_predP)\n",
        "plt.xlabel('Y Test')\n",
        "plt.ylabel('Predicted Y')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Predicted Y')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSa6Jq5sWKDK",
        "outputId": "83f19daa-b772-4ee0-fe08-1a5e6fbf1ebd"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "Sregressor = SVR(kernel = 'rbf')\n",
        "Sregressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
              "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8lMVG22WKDN"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlF5PDz9WKDP"
      },
      "source": [
        "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001]} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfpDGyCpWKDR",
        "outputId": "6270b4ac-dd4c-4e78-bea1-ad92e194f700"
      },
      "source": [
        "grid = GridSearchCV(SVR(),param_grid,refit=True,verbose=2)\n",
        "grid.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "[CV] C=0.1, gamma=1 ..................................................\n",
            "[CV] ................................... C=0.1, gamma=1, total=   0.0s\n",
            "[CV] C=0.1, gamma=1 ..................................................\n",
            "[CV] ................................... C=0.1, gamma=1, total=   0.0s\n",
            "[CV] C=0.1, gamma=1 ..................................................\n",
            "[CV] ................................... C=0.1, gamma=1, total=   0.0s\n",
            "[CV] C=0.1, gamma=1 ..................................................\n",
            "[CV] ................................... C=0.1, gamma=1, total=   0.0s\n",
            "[CV] C=0.1, gamma=1 ..................................................\n",
            "[CV] ................................... C=0.1, gamma=1, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1 ................................................\n",
            "[CV] ................................. C=0.1, gamma=0.1, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1 ................................................\n",
            "[CV] ................................. C=0.1, gamma=0.1, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1 ................................................\n",
            "[CV] ................................. C=0.1, gamma=0.1, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1 ................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=0.1, gamma=0.1, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1 ................................................\n",
            "[CV] ................................. C=0.1, gamma=0.1, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01 ...............................................\n",
            "[CV] ................................ C=0.1, gamma=0.01, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01 ...............................................\n",
            "[CV] ................................ C=0.1, gamma=0.01, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01 ...............................................\n",
            "[CV] ................................ C=0.1, gamma=0.01, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01 ...............................................\n",
            "[CV] ................................ C=0.1, gamma=0.01, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01 ...............................................\n",
            "[CV] ................................ C=0.1, gamma=0.01, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001 ..............................................\n",
            "[CV] ............................... C=0.1, gamma=0.001, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001 ..............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, gamma=0.001, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001 ..............................................\n",
            "[CV] ............................... C=0.1, gamma=0.001, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001 ..............................................\n",
            "[CV] ............................... C=0.1, gamma=0.001, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001 ..............................................\n",
            "[CV] ............................... C=0.1, gamma=0.001, total=   0.0s\n",
            "[CV] C=1, gamma=1 ....................................................\n",
            "[CV] ..................................... C=1, gamma=1, total=   0.0s\n",
            "[CV] C=1, gamma=1 ....................................................\n",
            "[CV] ..................................... C=1, gamma=1, total=   0.0s\n",
            "[CV] C=1, gamma=1 ....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ..................................... C=1, gamma=1, total=   0.0s\n",
            "[CV] C=1, gamma=1 ....................................................\n",
            "[CV] ..................................... C=1, gamma=1, total=   0.0s\n",
            "[CV] C=1, gamma=1 ....................................................\n",
            "[CV] ..................................... C=1, gamma=1, total=   0.0s\n",
            "[CV] C=1, gamma=0.1 ..................................................\n",
            "[CV] ................................... C=1, gamma=0.1, total=   0.0s\n",
            "[CV] C=1, gamma=0.1 ..................................................\n",
            "[CV] ................................... C=1, gamma=0.1, total=   0.0s\n",
            "[CV] C=1, gamma=0.1 ..................................................\n",
            "[CV] ................................... C=1, gamma=0.1, total=   0.0s\n",
            "[CV] C=1, gamma=0.1 ..................................................\n",
            "[CV] ................................... C=1, gamma=0.1, total=   0.0s\n",
            "[CV] C=1, gamma=0.1 ..................................................\n",
            "[CV] ................................... C=1, gamma=0.1, total=   0.0s\n",
            "[CV] C=1, gamma=0.01 .................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................. C=1, gamma=0.01, total=   0.0s\n",
            "[CV] C=1, gamma=0.01 .................................................\n",
            "[CV] .................................. C=1, gamma=0.01, total=   0.0s\n",
            "[CV] C=1, gamma=0.01 .................................................\n",
            "[CV] .................................. C=1, gamma=0.01, total=   0.0s\n",
            "[CV] C=1, gamma=0.01 .................................................\n",
            "[CV] .................................. C=1, gamma=0.01, total=   0.0s\n",
            "[CV] C=1, gamma=0.01 .................................................\n",
            "[CV] .................................. C=1, gamma=0.01, total=   0.0s\n",
            "[CV] C=1, gamma=0.001 ................................................\n",
            "[CV] ................................. C=1, gamma=0.001, total=   0.0s\n",
            "[CV] C=1, gamma=0.001 ................................................\n",
            "[CV] ................................. C=1, gamma=0.001, total=   0.0s\n",
            "[CV] C=1, gamma=0.001 ................................................\n",
            "[CV] ................................. C=1, gamma=0.001, total=   0.0s\n",
            "[CV] C=1, gamma=0.001 ................................................\n",
            "[CV] ................................. C=1, gamma=0.001, total=   0.0s\n",
            "[CV] C=1, gamma=0.001 ................................................\n",
            "[CV] ................................. C=1, gamma=0.001, total=   0.0s\n",
            "[CV] C=10, gamma=1 ...................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................... C=10, gamma=1, total=   0.0s\n",
            "[CV] C=10, gamma=1 ...................................................\n",
            "[CV] .................................... C=10, gamma=1, total=   0.0s\n",
            "[CV] C=10, gamma=1 ...................................................\n",
            "[CV] .................................... C=10, gamma=1, total=   0.0s\n",
            "[CV] C=10, gamma=1 ...................................................\n",
            "[CV] .................................... C=10, gamma=1, total=   0.0s\n",
            "[CV] C=10, gamma=1 ...................................................\n",
            "[CV] .................................... C=10, gamma=1, total=   0.0s\n",
            "[CV] C=10, gamma=0.1 .................................................\n",
            "[CV] .................................. C=10, gamma=0.1, total=   0.0s\n",
            "[CV] C=10, gamma=0.1 .................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................. C=10, gamma=0.1, total=   0.1s\n",
            "[CV] C=10, gamma=0.1 .................................................\n",
            "[CV] .................................. C=10, gamma=0.1, total=   0.0s\n",
            "[CV] C=10, gamma=0.1 .................................................\n",
            "[CV] .................................. C=10, gamma=0.1, total=   0.0s\n",
            "[CV] C=10, gamma=0.1 .................................................\n",
            "[CV] .................................. C=10, gamma=0.1, total=   0.0s\n",
            "[CV] C=10, gamma=0.01 ................................................\n",
            "[CV] ................................. C=10, gamma=0.01, total=   0.0s\n",
            "[CV] C=10, gamma=0.01 ................................................\n",
            "[CV] ................................. C=10, gamma=0.01, total=   0.0s\n",
            "[CV] C=10, gamma=0.01 ................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=10, gamma=0.01, total=   0.0s\n",
            "[CV] C=10, gamma=0.01 ................................................\n",
            "[CV] ................................. C=10, gamma=0.01, total=   0.0s\n",
            "[CV] C=10, gamma=0.01 ................................................\n",
            "[CV] ................................. C=10, gamma=0.01, total=   0.0s\n",
            "[CV] C=10, gamma=0.001 ...............................................\n",
            "[CV] ................................ C=10, gamma=0.001, total=   0.0s\n",
            "[CV] C=10, gamma=0.001 ...............................................\n",
            "[CV] ................................ C=10, gamma=0.001, total=   0.0s\n",
            "[CV] C=10, gamma=0.001 ...............................................\n",
            "[CV] ................................ C=10, gamma=0.001, total=   0.0s\n",
            "[CV] C=10, gamma=0.001 ...............................................\n",
            "[CV] ................................ C=10, gamma=0.001, total=   0.0s\n",
            "[CV] C=10, gamma=0.001 ...............................................\n",
            "[CV] ................................ C=10, gamma=0.001, total=   0.0s\n",
            "[CV] C=100, gamma=1 ..................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................... C=100, gamma=1, total=   0.1s\n",
            "[CV] C=100, gamma=1 ..................................................\n",
            "[CV] ................................... C=100, gamma=1, total=   0.0s\n",
            "[CV] C=100, gamma=1 ..................................................\n",
            "[CV] ................................... C=100, gamma=1, total=   0.0s\n",
            "[CV] C=100, gamma=1 ..................................................\n",
            "[CV] ................................... C=100, gamma=1, total=   0.1s\n",
            "[CV] C=100, gamma=1 ..................................................\n",
            "[CV] ................................... C=100, gamma=1, total=   0.0s\n",
            "[CV] C=100, gamma=0.1 ................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=100, gamma=0.1, total=   0.2s\n",
            "[CV] C=100, gamma=0.1 ................................................\n",
            "[CV] ................................. C=100, gamma=0.1, total=   0.2s\n",
            "[CV] C=100, gamma=0.1 ................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=100, gamma=0.1, total=   0.2s\n",
            "[CV] C=100, gamma=0.1 ................................................\n",
            "[CV] ................................. C=100, gamma=0.1, total=   0.2s\n",
            "[CV] C=100, gamma=0.1 ................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=100, gamma=0.1, total=   0.2s\n",
            "[CV] C=100, gamma=0.01 ...............................................\n",
            "[CV] ................................ C=100, gamma=0.01, total=   0.0s\n",
            "[CV] C=100, gamma=0.01 ...............................................\n",
            "[CV] ................................ C=100, gamma=0.01, total=   0.0s\n",
            "[CV] C=100, gamma=0.01 ...............................................\n",
            "[CV] ................................ C=100, gamma=0.01, total=   0.0s\n",
            "[CV] C=100, gamma=0.01 ...............................................\n",
            "[CV] ................................ C=100, gamma=0.01, total=   0.0s\n",
            "[CV] C=100, gamma=0.01 ...............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=100, gamma=0.01, total=   0.0s\n",
            "[CV] C=100, gamma=0.001 ..............................................\n",
            "[CV] ............................... C=100, gamma=0.001, total=   0.0s\n",
            "[CV] C=100, gamma=0.001 ..............................................\n",
            "[CV] ............................... C=100, gamma=0.001, total=   0.0s\n",
            "[CV] C=100, gamma=0.001 ..............................................\n",
            "[CV] ............................... C=100, gamma=0.001, total=   0.0s\n",
            "[CV] C=100, gamma=0.001 ..............................................\n",
            "[CV] ............................... C=100, gamma=0.001, total=   0.0s\n",
            "[CV] C=100, gamma=0.001 ..............................................\n",
            "[CV] ............................... C=100, gamma=0.001, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    3.1s finished\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
              "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
              "                           max_iter=-1, shrinking=True, tol=0.001,\n",
              "                           verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.1, 1, 10, 100],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFxuTIfmWKDX",
        "outputId": "37ec3450-02d1-46e0-f4da-998bed13a107"
      },
      "source": [
        "grid.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.01,\n",
              "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0soCkbwWKDZ",
        "outputId": "1bd4ab88-0f9d-40ec-acce-3181a63a00e2"
      },
      "source": [
        "Sregressor = SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.01,\n",
        "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
        "Sregressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.01,\n",
              "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjvLD-aVWKDc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNYNb7XwWKDf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkeUW0LeWKDh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGf4LXiGWKDl"
      },
      "source": [
        "y_predS = Sregressor.predict((X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Bi_i4_WKDn",
        "outputId": "6a77f05e-62dd-4d1a-ad1d-2f5a30239991"
      },
      "source": [
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_predS.reshape(len(y_predS),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11.78 11.95]\n",
            " [12.72 12.69]\n",
            " [11.67 11.65]\n",
            " [11.93 11.98]\n",
            " [12.75 12.66]\n",
            " [11.31 11.23]\n",
            " [12.33 12.65]\n",
            " [11.94 11.89]\n",
            " [11.3  11.34]\n",
            " [11.72 11.82]\n",
            " [11.9  11.88]\n",
            " [11.68 11.78]\n",
            " [11.46 11.3 ]\n",
            " [12.27 12.27]\n",
            " [12.07 12.11]\n",
            " [11.82 11.81]\n",
            " [12.22 12.12]\n",
            " [11.77 11.81]\n",
            " [11.62 11.68]\n",
            " [12.29 12.33]\n",
            " [12.12 11.95]\n",
            " [12.26 12.25]\n",
            " [12.12 12.06]\n",
            " [11.75 11.77]\n",
            " [12.27 12.17]\n",
            " [11.94 11.94]\n",
            " [12.21 12.11]\n",
            " [11.63 11.86]\n",
            " [12.1  12.11]\n",
            " [12.27 12.25]\n",
            " [11.74 11.75]\n",
            " [12.49 12.56]\n",
            " [12.24 12.21]\n",
            " [11.58 11.82]\n",
            " [12.5  12.45]\n",
            " [11.88 11.85]\n",
            " [11.96 11.84]\n",
            " [12.29 12.3 ]\n",
            " [12.57 12.64]\n",
            " [11.42 11.48]\n",
            " [11.73 11.65]\n",
            " [12.39 12.23]\n",
            " [11.63 11.69]\n",
            " [12.71 12.44]\n",
            " [11.73 11.76]\n",
            " [11.83 11.67]\n",
            " [11.58 11.65]\n",
            " [11.7  11.75]\n",
            " [12.9  13.02]\n",
            " [11.78 11.88]\n",
            " [11.65 11.69]\n",
            " [12.25 12.19]\n",
            " [11.67 11.65]\n",
            " [12.65 12.57]\n",
            " [11.96 11.88]\n",
            " [12.37 12.47]\n",
            " [12.26 12.27]\n",
            " [11.95 12.07]\n",
            " [11.85 11.58]\n",
            " [11.58 11.59]\n",
            " [11.08 11.13]\n",
            " [11.9  11.94]\n",
            " [12.66 12.67]\n",
            " [12.47 12.48]\n",
            " [12.68 12.55]\n",
            " [12.32 12.4 ]\n",
            " [11.58 11.6 ]\n",
            " [12.72 12.63]\n",
            " [11.63 11.45]\n",
            " [12.03 12.08]\n",
            " [11.77 11.69]\n",
            " [11.79 11.81]\n",
            " [11.56 11.6 ]\n",
            " [11.39 11.45]\n",
            " [13.   13.32]\n",
            " [12.16 12.06]\n",
            " [12.62 12.76]\n",
            " [12.65 12.74]\n",
            " [11.79 11.86]\n",
            " [11.65 11.74]\n",
            " [11.55 11.68]\n",
            " [11.46 11.11]\n",
            " [11.73 11.64]\n",
            " [11.53 11.42]\n",
            " [11.89 11.92]\n",
            " [11.73 11.8 ]\n",
            " [12.51 12.49]\n",
            " [12.24 12.15]\n",
            " [11.91 11.96]\n",
            " [12.18 11.96]\n",
            " [11.87 11.94]\n",
            " [11.91 11.93]\n",
            " [11.67 11.73]\n",
            " [12.47 12.61]\n",
            " [11.62 11.82]\n",
            " [12.16 12.04]\n",
            " [11.95 12.23]\n",
            " [12.15 12.12]\n",
            " [12.24 12.23]\n",
            " [12.4  12.47]\n",
            " [12.1  12.  ]\n",
            " [12.24 12.32]\n",
            " [12.46 12.4 ]\n",
            " [11.69 11.79]\n",
            " [12.15 12.18]\n",
            " [12.09 11.96]\n",
            " [11.92 11.96]\n",
            " [12.45 12.52]\n",
            " [11.84 11.88]\n",
            " [12.09 11.81]\n",
            " [11.11 11.  ]\n",
            " [11.7  11.73]\n",
            " [11.77 11.75]\n",
            " [11.74 11.83]\n",
            " [12.24 12.27]\n",
            " [11.65 11.69]\n",
            " [11.52 11.59]\n",
            " [11.72 11.72]\n",
            " [11.83 11.63]\n",
            " [12.52 12.56]\n",
            " [11.76 11.8 ]\n",
            " [11.93 11.91]\n",
            " [12.13 12.04]\n",
            " [12.06 12.24]\n",
            " [12.25 12.07]\n",
            " [11.67 11.83]\n",
            " [12.33 12.37]\n",
            " [11.48 11.28]\n",
            " [11.9  11.88]\n",
            " [12.11 12.  ]\n",
            " [12.14 12.13]\n",
            " [12.81 12.82]\n",
            " [12.22 12.2 ]\n",
            " [11.75 11.55]\n",
            " [11.   10.47]\n",
            " [12.84 12.73]\n",
            " [12.66 12.81]\n",
            " [11.83 11.78]\n",
            " [12.36 12.35]\n",
            " [13.14 13.53]\n",
            " [12.72 12.91]\n",
            " [11.72 11.79]\n",
            " [12.12 12.09]\n",
            " [11.97 11.82]\n",
            " [11.67 11.88]\n",
            " [11.72 11.72]\n",
            " [12.25 12.43]\n",
            " [12.18 12.14]\n",
            " [11.68 11.8 ]\n",
            " [11.31 11.11]\n",
            " [11.7  11.83]\n",
            " [11.88 11.95]\n",
            " [12.37 12.21]\n",
            " [11.95 11.95]\n",
            " [11.36 11.42]\n",
            " [11.79 11.82]\n",
            " [11.86 11.6 ]\n",
            " [11.97 11.85]\n",
            " [11.41 11.36]\n",
            " [11.84 11.79]\n",
            " [12.26 12.1 ]\n",
            " [11.84 11.88]\n",
            " [12.6  12.59]\n",
            " [11.97 11.88]\n",
            " [11.63 11.68]\n",
            " [11.72 11.86]\n",
            " [12.33 12.38]\n",
            " [12.67 12.53]\n",
            " [12.9  13.23]\n",
            " [12.25 12.41]\n",
            " [12.92 12.79]\n",
            " [11.44 11.54]\n",
            " [11.69 11.53]\n",
            " [11.95 11.93]\n",
            " [12.63 12.56]\n",
            " [11.83 11.81]\n",
            " [11.82 11.64]\n",
            " [12.31 12.14]\n",
            " [11.7  11.74]\n",
            " [12.06 12.09]\n",
            " [11.99 12.1 ]\n",
            " [11.44 10.93]\n",
            " [11.76 11.79]\n",
            " [11.86 11.81]\n",
            " [12.43 12.45]\n",
            " [11.87 11.85]\n",
            " [12.48 12.51]\n",
            " [12.4  12.42]\n",
            " [12.23 12.22]\n",
            " [11.42 11.23]\n",
            " [11.69 11.72]\n",
            " [11.62 11.59]\n",
            " [11.93 11.98]\n",
            " [11.89 12.05]\n",
            " [12.23 12.19]\n",
            " [12.09 12.32]\n",
            " [12.28 12.19]\n",
            " [11.35 10.6 ]\n",
            " [12.25 12.06]\n",
            " [11.83 11.95]\n",
            " [12.41 12.54]\n",
            " [12.16 12.07]\n",
            " [11.61 11.9 ]\n",
            " [12.65 12.66]\n",
            " [12.23 12.13]\n",
            " [11.68 11.82]\n",
            " [12.32 12.39]\n",
            " [11.79 11.84]\n",
            " [12.03 11.85]\n",
            " [11.62 11.61]\n",
            " [12.4  12.32]\n",
            " [11.95 11.87]\n",
            " [11.65 11.77]\n",
            " [11.99 12.06]\n",
            " [12.37 12.39]\n",
            " [12.44 12.48]\n",
            " [12.34 12.18]\n",
            " [11.83 11.87]\n",
            " [11.9  11.78]\n",
            " [11.86 11.74]\n",
            " [11.76 11.87]\n",
            " [12.32 12.45]\n",
            " [12.25 12.29]\n",
            " [11.52 11.1 ]\n",
            " [12.39 12.21]\n",
            " [11.84 11.95]\n",
            " [11.46 11.13]\n",
            " [11.6  11.07]\n",
            " [12.03 12.06]\n",
            " [11.45 11.54]\n",
            " [11.5  11.35]\n",
            " [12.09 12.02]\n",
            " [11.71 11.7 ]\n",
            " [11.69 11.81]\n",
            " [12.31 12.3 ]\n",
            " [11.78 11.94]\n",
            " [12.19 12.18]\n",
            " [11.97 11.9 ]\n",
            " [12.35 12.53]\n",
            " [11.74 11.87]\n",
            " [11.58 11.57]\n",
            " [12.44 12.4 ]\n",
            " [12.16 12.18]\n",
            " [12.91 12.99]\n",
            " [12.11 12.13]\n",
            " [11.75 11.59]\n",
            " [11.99 12.01]\n",
            " [12.14 12.08]\n",
            " [11.73 11.77]\n",
            " [11.48 11.65]\n",
            " [12.14 12.17]\n",
            " [12.12 11.98]\n",
            " [11.8  11.88]\n",
            " [11.44 11.36]\n",
            " [11.76 11.97]\n",
            " [11.87 11.76]\n",
            " [11.68 11.65]\n",
            " [11.53 11.69]\n",
            " [12.05 12.08]\n",
            " [12.42 12.39]\n",
            " [12.64 12.89]\n",
            " [12.04 12.01]\n",
            " [11.77 11.76]\n",
            " [12.31 12.52]\n",
            " [12.6  12.65]\n",
            " [12.36 12.27]\n",
            " [11.99 11.94]\n",
            " [11.88 11.88]\n",
            " [11.65 11.65]\n",
            " [12.09 12.1 ]\n",
            " [12.92 13.05]\n",
            " [12.27 12.1 ]\n",
            " [12.36 12.44]\n",
            " [11.52 11.35]\n",
            " [11.59 11.53]\n",
            " [11.76 11.91]\n",
            " [11.98 11.83]\n",
            " [12.59 12.67]\n",
            " [12.36 11.87]\n",
            " [11.89 11.85]\n",
            " [12.23 12.17]\n",
            " [11.4  11.43]\n",
            " [12.22 12.19]\n",
            " [11.6  11.6 ]\n",
            " [12.62 12.6 ]\n",
            " [12.09 12.13]\n",
            " [12.26 12.35]\n",
            " [11.58 11.4 ]\n",
            " [12.48 12.47]\n",
            " [12.26 12.15]\n",
            " [11.77 11.59]\n",
            " [11.61 11.73]\n",
            " [11.83 11.88]\n",
            " [12.07 12.09]\n",
            " [11.39 11.35]\n",
            " [12.04 12.07]\n",
            " [11.88 11.75]\n",
            " [11.74 11.92]\n",
            " [12.17 12.07]\n",
            " [11.63 11.74]\n",
            " [12.12 12.08]\n",
            " [12.35 12.32]\n",
            " [11.74 11.77]\n",
            " [11.87 11.98]\n",
            " [12.12 11.96]\n",
            " [12.23 12.23]\n",
            " [11.94 11.85]\n",
            " [12.29 12.21]\n",
            " [12.39 12.29]\n",
            " [11.63 11.74]\n",
            " [11.84 11.98]\n",
            " [12.26 12.12]\n",
            " [11.49 11.48]\n",
            " [12.2  12.21]\n",
            " [11.74 11.91]\n",
            " [12.14 12.09]\n",
            " [12.12 12.13]\n",
            " [12.04 12.01]\n",
            " [12.55 12.72]\n",
            " [11.38 11.38]\n",
            " [12.29 12.36]\n",
            " [11.83 11.91]\n",
            " [11.78 11.8 ]\n",
            " [11.43 11.49]\n",
            " [12.2  12.24]\n",
            " [12.01 11.92]\n",
            " [11.75 11.81]\n",
            " [12.33 12.14]\n",
            " [12.05 11.92]\n",
            " [11.52 11.66]\n",
            " [12.03 11.94]\n",
            " [11.94 12.01]\n",
            " [11.75 11.78]\n",
            " [12.24 12.24]\n",
            " [12.03 11.89]\n",
            " [11.73 11.75]\n",
            " [11.91 11.84]\n",
            " [11.53 11.64]\n",
            " [11.45 11.28]\n",
            " [12.27 12.11]\n",
            " [12.14 12.14]\n",
            " [11.79 11.77]\n",
            " [11.74 11.98]\n",
            " [12.11 12.07]\n",
            " [12.39 12.3 ]\n",
            " [12.78 12.64]\n",
            " [12.81 12.83]\n",
            " [11.64 11.51]\n",
            " [12.36 12.43]\n",
            " [11.7  11.88]\n",
            " [12.39 12.69]\n",
            " [12.82 12.85]\n",
            " [12.44 12.52]\n",
            " [12.12 12.1 ]\n",
            " [12.41 12.41]\n",
            " [11.76 11.93]\n",
            " [11.72 11.81]\n",
            " [11.48 11.45]\n",
            " [12.27 12.28]\n",
            " [12.72 12.77]\n",
            " [12.15 12.18]\n",
            " [11.79 11.7 ]\n",
            " [12.4  12.34]\n",
            " [12.34 12.42]\n",
            " [11.75 11.73]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-EBE0ghWKDp",
        "outputId": "86ecb862-b107-4025-b7eb-55398c6d992e"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print('The accuracy is {:.0%}'.format(r2_score(y_test, y_predS)))\n",
        "print('The mean squared error is {:.0%}'.format(mean_squared_error(y_test, y_predS)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is 90%\n",
            "The mean squared error is 2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXB_ObhcWKDr",
        "outputId": "2659ca26-a04b-46d7-b279-4c7220b68a0c"
      },
      "source": [
        "plt.scatter(y_test,y_predS)\n",
        "plt.xlabel('Y Test')\n",
        "plt.ylabel('Predicted Y')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Predicted Y')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGbLiZ9rWKDv",
        "outputId": "dc82ae63-0656-4082-f64b-7a53fe0a1e5e"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "Dregressor = DecisionTreeRegressor(random_state = 42, criterion = 'mse')\n",
        "Dregressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=42, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f97SJIKXWKDy",
        "outputId": "40025061-4ce2-4afd-cb95-c809918817b5"
      },
      "source": [
        "Dregressor = DecisionTreeRegressor(random_state=42)\n",
        "Dregressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=42, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0e1bu22WKD2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIpE0QXUWKD3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk7X3gZwWKD6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqyKutVIWKD-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LWNyA8wWKEA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ywRpF-RWKEF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YiyoTczWKEH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQEi5cDmWKEJ"
      },
      "source": [
        "y_predD = Dregressor.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUUgGorHWKEM",
        "outputId": "a91db0c4-467a-47c3-d131-f60b0b2406ab"
      },
      "source": [
        "\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_predD.reshape(len(y_predD),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11.85 11.95]\n",
            " [12.75 12.69]\n",
            " [11.51 11.65]\n",
            " [12.   11.98]\n",
            " [12.55 12.66]\n",
            " [11.68 11.23]\n",
            " [12.43 12.65]\n",
            " [11.91 11.89]\n",
            " [11.3  11.34]\n",
            " [11.68 11.82]\n",
            " [12.15 11.88]\n",
            " [11.69 11.78]\n",
            " [11.31 11.3 ]\n",
            " [12.3  12.27]\n",
            " [11.97 12.11]\n",
            " [11.79 11.81]\n",
            " [12.18 12.12]\n",
            " [11.88 11.81]\n",
            " [11.51 11.68]\n",
            " [12.24 12.33]\n",
            " [12.1  11.95]\n",
            " [12.3  12.25]\n",
            " [12.12 12.06]\n",
            " [11.79 11.77]\n",
            " [12.15 12.17]\n",
            " [12.1  11.94]\n",
            " [12.21 12.11]\n",
            " [11.41 11.86]\n",
            " [12.11 12.11]\n",
            " [12.22 12.25]\n",
            " [12.08 11.75]\n",
            " [12.51 12.56]\n",
            " [12.04 12.21]\n",
            " [11.67 11.82]\n",
            " [12.6  12.45]\n",
            " [11.82 11.85]\n",
            " [11.87 11.84]\n",
            " [12.18 12.3 ]\n",
            " [12.58 12.64]\n",
            " [11.44 11.48]\n",
            " [11.81 11.65]\n",
            " [12.36 12.23]\n",
            " [11.7  11.69]\n",
            " [12.86 12.44]\n",
            " [11.77 11.76]\n",
            " [11.83 11.67]\n",
            " [11.61 11.65]\n",
            " [11.79 11.75]\n",
            " [12.96 13.02]\n",
            " [11.75 11.88]\n",
            " [11.69 11.69]\n",
            " [12.03 12.19]\n",
            " [11.63 11.65]\n",
            " [12.54 12.57]\n",
            " [11.86 11.88]\n",
            " [12.27 12.47]\n",
            " [12.25 12.27]\n",
            " [11.93 12.07]\n",
            " [12.52 11.58]\n",
            " [11.04 11.59]\n",
            " [11.2  11.13]\n",
            " [12.   11.94]\n",
            " [12.69 12.67]\n",
            " [12.49 12.48]\n",
            " [12.83 12.55]\n",
            " [12.52 12.4 ]\n",
            " [11.6  11.6 ]\n",
            " [12.77 12.63]\n",
            " [11.34 11.45]\n",
            " [12.13 12.08]\n",
            " [11.69 11.69]\n",
            " [11.81 11.81]\n",
            " [11.65 11.6 ]\n",
            " [11.61 11.45]\n",
            " [13.13 13.32]\n",
            " [12.06 12.06]\n",
            " [12.72 12.76]\n",
            " [12.47 12.74]\n",
            " [11.97 11.86]\n",
            " [11.61 11.74]\n",
            " [11.33 11.68]\n",
            " [11.71 11.11]\n",
            " [11.77 11.64]\n",
            " [11.44 11.42]\n",
            " [12.06 11.92]\n",
            " [11.81 11.8 ]\n",
            " [12.44 12.49]\n",
            " [12.19 12.15]\n",
            " [11.91 11.96]\n",
            " [12.   11.96]\n",
            " [11.74 11.94]\n",
            " [12.15 11.93]\n",
            " [11.61 11.73]\n",
            " [12.43 12.61]\n",
            " [11.41 11.82]\n",
            " [12.01 12.04]\n",
            " [12.12 12.23]\n",
            " [12.01 12.12]\n",
            " [12.21 12.23]\n",
            " [12.17 12.47]\n",
            " [11.97 12.  ]\n",
            " [12.25 12.32]\n",
            " [12.33 12.4 ]\n",
            " [11.87 11.79]\n",
            " [11.71 12.18]\n",
            " [12.03 11.96]\n",
            " [11.87 11.96]\n",
            " [12.68 12.52]\n",
            " [11.74 11.88]\n",
            " [11.71 11.81]\n",
            " [10.86 11.  ]\n",
            " [11.34 11.73]\n",
            " [11.79 11.75]\n",
            " [11.81 11.83]\n",
            " [12.21 12.27]\n",
            " [11.33 11.69]\n",
            " [11.61 11.59]\n",
            " [11.7  11.72]\n",
            " [12.24 11.63]\n",
            " [12.51 12.56]\n",
            " [12.15 11.8 ]\n",
            " [11.91 11.91]\n",
            " [12.11 12.04]\n",
            " [12.1  12.24]\n",
            " [12.07 12.07]\n",
            " [11.79 11.83]\n",
            " [12.31 12.37]\n",
            " [11.6  11.28]\n",
            " [11.9  11.88]\n",
            " [12.18 12.  ]\n",
            " [12.12 12.13]\n",
            " [12.99 12.82]\n",
            " [12.22 12.2 ]\n",
            " [11.29 11.55]\n",
            " [10.54 10.47]\n",
            " [12.96 12.73]\n",
            " [12.69 12.81]\n",
            " [11.8  11.78]\n",
            " [12.31 12.35]\n",
            " [13.52 13.53]\n",
            " [13.09 12.91]\n",
            " [11.72 11.79]\n",
            " [11.98 12.09]\n",
            " [12.02 11.82]\n",
            " [11.77 11.88]\n",
            " [11.84 11.72]\n",
            " [12.28 12.43]\n",
            " [12.13 12.14]\n",
            " [11.57 11.8 ]\n",
            " [10.86 11.11]\n",
            " [11.88 11.83]\n",
            " [11.98 11.95]\n",
            " [12.39 12.21]\n",
            " [11.5  11.95]\n",
            " [11.74 11.42]\n",
            " [11.84 11.82]\n",
            " [11.41 11.6 ]\n",
            " [11.85 11.85]\n",
            " [11.68 11.36]\n",
            " [11.94 11.79]\n",
            " [12.26 12.1 ]\n",
            " [11.85 11.88]\n",
            " [12.6  12.59]\n",
            " [12.1  11.88]\n",
            " [11.69 11.68]\n",
            " [11.75 11.86]\n",
            " [12.15 12.38]\n",
            " [12.8  12.53]\n",
            " [13.09 13.23]\n",
            " [12.43 12.41]\n",
            " [12.69 12.79]\n",
            " [11.69 11.54]\n",
            " [11.81 11.53]\n",
            " [11.73 11.93]\n",
            " [12.74 12.56]\n",
            " [11.84 11.81]\n",
            " [11.85 11.64]\n",
            " [12.33 12.14]\n",
            " [11.68 11.74]\n",
            " [12.08 12.09]\n",
            " [11.97 12.1 ]\n",
            " [10.46 10.93]\n",
            " [11.51 11.79]\n",
            " [12.   11.81]\n",
            " [12.38 12.45]\n",
            " [11.67 11.85]\n",
            " [12.65 12.51]\n",
            " [12.07 12.42]\n",
            " [12.22 12.22]\n",
            " [11.33 11.23]\n",
            " [11.74 11.72]\n",
            " [11.73 11.59]\n",
            " [11.96 11.98]\n",
            " [11.69 12.05]\n",
            " [12.06 12.19]\n",
            " [11.79 12.32]\n",
            " [12.22 12.19]\n",
            " [11.63 10.6 ]\n",
            " [12.33 12.06]\n",
            " [11.88 11.95]\n",
            " [12.33 12.54]\n",
            " [12.1  12.07]\n",
            " [11.68 11.9 ]\n",
            " [12.92 12.66]\n",
            " [12.24 12.13]\n",
            " [11.92 11.82]\n",
            " [12.45 12.39]\n",
            " [11.77 11.84]\n",
            " [11.85 11.85]\n",
            " [11.51 11.61]\n",
            " [12.38 12.32]\n",
            " [11.98 11.87]\n",
            " [12.02 11.77]\n",
            " [12.13 12.06]\n",
            " [12.08 12.39]\n",
            " [12.26 12.48]\n",
            " [12.21 12.18]\n",
            " [11.86 11.87]\n",
            " [12.04 11.78]\n",
            " [11.87 11.74]\n",
            " [11.63 11.87]\n",
            " [12.17 12.45]\n",
            " [12.31 12.29]\n",
            " [11.73 11.1 ]\n",
            " [12.35 12.21]\n",
            " [11.85 11.95]\n",
            " [11.61 11.13]\n",
            " [11.53 11.07]\n",
            " [12.21 12.06]\n",
            " [11.71 11.54]\n",
            " [11.44 11.35]\n",
            " [12.03 12.02]\n",
            " [11.84 11.7 ]\n",
            " [11.7  11.81]\n",
            " [12.38 12.3 ]\n",
            " [11.79 11.94]\n",
            " [12.18 12.18]\n",
            " [11.96 11.9 ]\n",
            " [12.59 12.53]\n",
            " [11.51 11.87]\n",
            " [11.3  11.57]\n",
            " [12.4  12.4 ]\n",
            " [12.35 12.18]\n",
            " [12.96 12.99]\n",
            " [12.24 12.13]\n",
            " [12.1  11.59]\n",
            " [11.94 12.01]\n",
            " [11.95 12.08]\n",
            " [11.61 11.77]\n",
            " [11.7  11.65]\n",
            " [12.15 12.17]\n",
            " [12.1  11.98]\n",
            " [11.93 11.88]\n",
            " [11.7  11.36]\n",
            " [11.81 11.97]\n",
            " [11.76 11.76]\n",
            " [11.64 11.65]\n",
            " [11.63 11.69]\n",
            " [12.1  12.08]\n",
            " [12.38 12.39]\n",
            " [12.89 12.89]\n",
            " [11.98 12.01]\n",
            " [11.8  11.76]\n",
            " [12.39 12.52]\n",
            " [12.42 12.65]\n",
            " [12.24 12.27]\n",
            " [12.11 11.94]\n",
            " [11.82 11.88]\n",
            " [11.83 11.65]\n",
            " [12.03 12.1 ]\n",
            " [12.99 13.05]\n",
            " [12.15 12.1 ]\n",
            " [12.43 12.44]\n",
            " [11.33 11.35]\n",
            " [11.41 11.53]\n",
            " [11.84 11.91]\n",
            " [11.78 11.83]\n",
            " [12.37 12.67]\n",
            " [12.37 11.87]\n",
            " [11.68 11.85]\n",
            " [12.21 12.17]\n",
            " [11.68 11.43]\n",
            " [12.28 12.19]\n",
            " [11.7  11.6 ]\n",
            " [12.84 12.6 ]\n",
            " [12.13 12.13]\n",
            " [12.22 12.35]\n",
            " [11.74 11.4 ]\n",
            " [12.47 12.47]\n",
            " [12.1  12.15]\n",
            " [11.85 11.59]\n",
            " [11.48 11.73]\n",
            " [11.79 11.88]\n",
            " [12.03 12.09]\n",
            " [11.64 11.35]\n",
            " [11.8  12.07]\n",
            " [11.65 11.75]\n",
            " [11.63 11.92]\n",
            " [11.96 12.07]\n",
            " [11.7  11.74]\n",
            " [12.12 12.08]\n",
            " [12.36 12.32]\n",
            " [11.86 11.77]\n",
            " [11.88 11.98]\n",
            " [12.15 11.96]\n",
            " [12.1  12.23]\n",
            " [12.03 11.85]\n",
            " [12.38 12.21]\n",
            " [12.38 12.29]\n",
            " [11.67 11.74]\n",
            " [11.76 11.98]\n",
            " [12.31 12.12]\n",
            " [11.58 11.48]\n",
            " [11.84 12.21]\n",
            " [11.76 11.91]\n",
            " [12.01 12.09]\n",
            " [12.1  12.13]\n",
            " [12.05 12.01]\n",
            " [12.62 12.72]\n",
            " [11.61 11.38]\n",
            " [12.3  12.36]\n",
            " [11.63 11.91]\n",
            " [11.78 11.8 ]\n",
            " [11.65 11.49]\n",
            " [12.25 12.24]\n",
            " [12.03 11.92]\n",
            " [11.88 11.81]\n",
            " [12.43 12.14]\n",
            " [12.05 11.92]\n",
            " [11.48 11.66]\n",
            " [11.71 11.94]\n",
            " [11.56 12.01]\n",
            " [11.04 11.78]\n",
            " [12.15 12.24]\n",
            " [11.85 11.89]\n",
            " [11.8  11.75]\n",
            " [11.88 11.84]\n",
            " [11.68 11.64]\n",
            " [11.46 11.28]\n",
            " [12.34 12.11]\n",
            " [12.13 12.14]\n",
            " [11.78 11.77]\n",
            " [11.98 11.98]\n",
            " [12.24 12.07]\n",
            " [12.22 12.3 ]\n",
            " [12.96 12.64]\n",
            " [12.83 12.83]\n",
            " [11.53 11.51]\n",
            " [12.39 12.43]\n",
            " [11.84 11.88]\n",
            " [12.03 12.69]\n",
            " [12.93 12.85]\n",
            " [12.37 12.52]\n",
            " [12.   12.1 ]\n",
            " [12.35 12.41]\n",
            " [11.96 11.93]\n",
            " [11.82 11.81]\n",
            " [11.29 11.45]\n",
            " [12.24 12.28]\n",
            " [13.23 12.77]\n",
            " [12.26 12.18]\n",
            " [11.73 11.7 ]\n",
            " [12.45 12.34]\n",
            " [12.31 12.42]\n",
            " [11.82 11.73]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuAaV7nBWKEO",
        "outputId": "7147ebd4-114d-4e36-9973-aaf32e743d92"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print('The accuracy is {:.0%}'.format(r2_score(y_test, y_predD)))\n",
        "print('The mean squared error is {:.0%}'.format(mean_squared_error(y_test, y_predD)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is 77%\n",
            "The mean squared error is 4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb4u4S1ZWKEP",
        "outputId": "6b4832f2-a493-4a6e-ed2c-9983ed222b24"
      },
      "source": [
        "plt.scatter(y_test,y_predD)\n",
        "plt.xlabel('Y Test')\n",
        "plt.ylabel('Predicted Y')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Predicted Y')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChNb8sylWKES",
        "outputId": "04a680b8-b651-4e72-f96c-e1f828db1549"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "Rregressor = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
        "Rregressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
              "                      random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOCCN4TqWKEU",
        "outputId": "1e298177-7aab-4a62-c9f7-19520e491a29"
      },
      "source": [
        "param_gridR = {'n_estimators': [10,100,1000], 'max_depth': [10,100,1000]} \n",
        "gridR = GridSearchCV(RandomForestRegressor(),param_gridR,refit=True,scoring='neg_mean_squared_log_error', n_jobs = -1, cv= 5)\n",
        "gridR.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
              "                                             criterion='mse', max_depth=None,\n",
              "                                             max_features='auto',\n",
              "                                             max_leaf_nodes=None,\n",
              "                                             max_samples=None,\n",
              "                                             min_impurity_decrease=0.0,\n",
              "                                             min_impurity_split=None,\n",
              "                                             min_samples_leaf=1,\n",
              "                                             min_samples_split=2,\n",
              "                                             min_weight_fraction_leaf=0.0,\n",
              "                                             n_estimators=100, n_jobs=None,\n",
              "                                             oob_score=False, random_state=None,\n",
              "                                             verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'max_depth': [10, 100, 1000],\n",
              "                         'n_estimators': [10, 100, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_log_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "douNI4kKWKEY",
        "outputId": "7716e2b6-d2f4-4d23-ebea-44e441fe5b51"
      },
      "source": [
        "gridR.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=1000, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsFCg5m3WKEZ",
        "outputId": "829592e7-60c8-4ec2-ddf0-f62502ba245b"
      },
      "source": [
        "Rgridregressor = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
        "                      max_depth=1000, max_features='auto', max_leaf_nodes=None,\n",
        "                      max_samples=None, min_impurity_decrease=0.0,\n",
        "                      min_impurity_split=None, min_samples_leaf=1,\n",
        "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "                      n_estimators=1000, n_jobs=None, oob_score=False,\n",
        "                      random_state=None, verbose=0, warm_start=False)\n",
        "Rgridregressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=1000, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=1000, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1YAfuquWKEa"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYUWbLnJWKEc",
        "outputId": "58f85d4a-ad63-4023-c181-81facafa149a"
      },
      "source": [
        "cross_val_score(Rgridregressor,X_test, y_test, scoring='neg_mean_squared_log_error')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-8.34e-05, -1.87e-04, -2.08e-04, -1.40e-04, -1.05e-04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdQ9iV6sWKEe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csp-5Rn1WKEh",
        "outputId": "f7435bc9-d322-47a9-bda6-cca17118c507"
      },
      "source": [
        "y_predgrid = Rregressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_predgrid.reshape(len(y_predgrid),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11.85 11.95]\n",
            " [12.71 12.69]\n",
            " [11.55 11.65]\n",
            " [12.01 11.98]\n",
            " [12.71 12.66]\n",
            " [11.34 11.23]\n",
            " [12.33 12.65]\n",
            " [11.94 11.89]\n",
            " [11.31 11.34]\n",
            " [11.64 11.82]\n",
            " [11.9  11.88]\n",
            " [11.74 11.78]\n",
            " [11.5  11.3 ]\n",
            " [12.28 12.27]\n",
            " [12.1  12.11]\n",
            " [11.82 11.81]\n",
            " [12.18 12.12]\n",
            " [11.88 11.81]\n",
            " [11.61 11.68]\n",
            " [12.24 12.33]\n",
            " [12.   11.95]\n",
            " [12.33 12.25]\n",
            " [12.11 12.06]\n",
            " [11.8  11.77]\n",
            " [12.16 12.17]\n",
            " [12.05 11.94]\n",
            " [12.1  12.11]\n",
            " [11.47 11.86]\n",
            " [12.09 12.11]\n",
            " [12.29 12.25]\n",
            " [11.77 11.75]\n",
            " [12.46 12.56]\n",
            " [12.34 12.21]\n",
            " [11.68 11.82]\n",
            " [12.43 12.45]\n",
            " [11.91 11.85]\n",
            " [11.93 11.84]\n",
            " [12.27 12.3 ]\n",
            " [12.66 12.64]\n",
            " [11.55 11.48]\n",
            " [11.79 11.65]\n",
            " [12.41 12.23]\n",
            " [11.7  11.69]\n",
            " [12.87 12.44]\n",
            " [11.84 11.76]\n",
            " [11.76 11.67]\n",
            " [11.58 11.65]\n",
            " [11.75 11.75]\n",
            " [12.94 13.02]\n",
            " [11.91 11.88]\n",
            " [11.7  11.69]\n",
            " [12.06 12.19]\n",
            " [11.54 11.65]\n",
            " [12.81 12.57]\n",
            " [11.83 11.88]\n",
            " [12.36 12.47]\n",
            " [12.31 12.27]\n",
            " [11.96 12.07]\n",
            " [11.91 11.58]\n",
            " [11.58 11.59]\n",
            " [11.31 11.13]\n",
            " [11.89 11.94]\n",
            " [12.72 12.67]\n",
            " [12.44 12.48]\n",
            " [12.7  12.55]\n",
            " [12.28 12.4 ]\n",
            " [11.52 11.6 ]\n",
            " [12.74 12.63]\n",
            " [11.55 11.45]\n",
            " [12.03 12.08]\n",
            " [11.76 11.69]\n",
            " [11.87 11.81]\n",
            " [11.67 11.6 ]\n",
            " [11.5  11.45]\n",
            " [13.06 13.32]\n",
            " [12.07 12.06]\n",
            " [12.71 12.76]\n",
            " [12.62 12.74]\n",
            " [11.9  11.86]\n",
            " [11.7  11.74]\n",
            " [11.46 11.68]\n",
            " [11.49 11.11]\n",
            " [11.84 11.64]\n",
            " [11.63 11.42]\n",
            " [12.02 11.92]\n",
            " [11.75 11.8 ]\n",
            " [12.43 12.49]\n",
            " [12.09 12.15]\n",
            " [11.88 11.96]\n",
            " [12.07 11.96]\n",
            " [11.82 11.94]\n",
            " [12.08 11.93]\n",
            " [11.68 11.73]\n",
            " [12.49 12.61]\n",
            " [11.71 11.82]\n",
            " [12.12 12.04]\n",
            " [11.95 12.23]\n",
            " [12.   12.12]\n",
            " [12.28 12.23]\n",
            " [12.25 12.47]\n",
            " [12.04 12.  ]\n",
            " [12.28 12.32]\n",
            " [12.32 12.4 ]\n",
            " [11.92 11.79]\n",
            " [12.   12.18]\n",
            " [12.01 11.96]\n",
            " [11.88 11.96]\n",
            " [12.54 12.52]\n",
            " [11.84 11.88]\n",
            " [11.99 11.81]\n",
            " [10.89 11.  ]\n",
            " [11.72 11.73]\n",
            " [11.76 11.75]\n",
            " [11.78 11.83]\n",
            " [12.3  12.27]\n",
            " [11.57 11.69]\n",
            " [11.57 11.59]\n",
            " [11.7  11.72]\n",
            " [11.8  11.63]\n",
            " [12.46 12.56]\n",
            " [12.06 11.8 ]\n",
            " [11.88 11.91]\n",
            " [12.11 12.04]\n",
            " [12.06 12.24]\n",
            " [12.11 12.07]\n",
            " [11.73 11.83]\n",
            " [12.37 12.37]\n",
            " [11.54 11.28]\n",
            " [11.93 11.88]\n",
            " [12.17 12.  ]\n",
            " [12.1  12.13]\n",
            " [12.83 12.82]\n",
            " [12.28 12.2 ]\n",
            " [11.61 11.55]\n",
            " [11.15 10.47]\n",
            " [12.78 12.73]\n",
            " [12.69 12.81]\n",
            " [11.71 11.78]\n",
            " [12.32 12.35]\n",
            " [13.31 13.53]\n",
            " [13.01 12.91]\n",
            " [11.72 11.79]\n",
            " [12.07 12.09]\n",
            " [11.92 11.82]\n",
            " [11.82 11.88]\n",
            " [11.6  11.72]\n",
            " [12.34 12.43]\n",
            " [12.13 12.14]\n",
            " [11.65 11.8 ]\n",
            " [11.18 11.11]\n",
            " [11.74 11.83]\n",
            " [11.94 11.95]\n",
            " [12.32 12.21]\n",
            " [11.8  11.95]\n",
            " [11.26 11.42]\n",
            " [11.81 11.82]\n",
            " [11.78 11.6 ]\n",
            " [11.9  11.85]\n",
            " [11.41 11.36]\n",
            " [11.95 11.79]\n",
            " [12.28 12.1 ]\n",
            " [11.78 11.88]\n",
            " [12.5  12.59]\n",
            " [11.96 11.88]\n",
            " [11.72 11.68]\n",
            " [11.78 11.86]\n",
            " [12.25 12.38]\n",
            " [12.57 12.53]\n",
            " [13.2  13.23]\n",
            " [12.35 12.41]\n",
            " [12.84 12.79]\n",
            " [11.49 11.54]\n",
            " [11.77 11.53]\n",
            " [11.94 11.93]\n",
            " [12.82 12.56]\n",
            " [11.94 11.81]\n",
            " [11.92 11.64]\n",
            " [12.27 12.14]\n",
            " [11.75 11.74]\n",
            " [12.06 12.09]\n",
            " [12.12 12.1 ]\n",
            " [11.49 10.93]\n",
            " [11.84 11.79]\n",
            " [12.01 11.81]\n",
            " [12.44 12.45]\n",
            " [11.86 11.85]\n",
            " [12.48 12.51]\n",
            " [12.2  12.42]\n",
            " [12.2  12.22]\n",
            " [11.3  11.23]\n",
            " [11.74 11.72]\n",
            " [11.59 11.59]\n",
            " [11.86 11.98]\n",
            " [11.94 12.05]\n",
            " [12.11 12.19]\n",
            " [11.86 12.32]\n",
            " [12.19 12.19]\n",
            " [11.49 10.6 ]\n",
            " [12.21 12.06]\n",
            " [11.89 11.95]\n",
            " [12.32 12.54]\n",
            " [12.08 12.07]\n",
            " [11.69 11.9 ]\n",
            " [12.83 12.66]\n",
            " [12.21 12.13]\n",
            " [11.8  11.82]\n",
            " [12.38 12.39]\n",
            " [11.85 11.84]\n",
            " [11.86 11.85]\n",
            " [11.59 11.61]\n",
            " [12.39 12.32]\n",
            " [11.98 11.87]\n",
            " [11.64 11.77]\n",
            " [12.04 12.06]\n",
            " [12.16 12.39]\n",
            " [12.45 12.48]\n",
            " [12.18 12.18]\n",
            " [11.91 11.87]\n",
            " [11.9  11.78]\n",
            " [11.81 11.74]\n",
            " [11.7  11.87]\n",
            " [12.23 12.45]\n",
            " [12.23 12.29]\n",
            " [11.55 11.1 ]\n",
            " [12.47 12.21]\n",
            " [11.92 11.95]\n",
            " [11.57 11.13]\n",
            " [11.65 11.07]\n",
            " [12.14 12.06]\n",
            " [11.42 11.54]\n",
            " [11.63 11.35]\n",
            " [12.08 12.02]\n",
            " [11.73 11.7 ]\n",
            " [11.58 11.81]\n",
            " [12.31 12.3 ]\n",
            " [11.67 11.94]\n",
            " [12.22 12.18]\n",
            " [11.86 11.9 ]\n",
            " [12.38 12.53]\n",
            " [11.6  11.87]\n",
            " [11.48 11.57]\n",
            " [12.58 12.4 ]\n",
            " [12.25 12.18]\n",
            " [12.95 12.99]\n",
            " [12.18 12.13]\n",
            " [11.7  11.59]\n",
            " [11.98 12.01]\n",
            " [11.96 12.08]\n",
            " [11.77 11.77]\n",
            " [11.44 11.65]\n",
            " [12.19 12.17]\n",
            " [12.04 11.98]\n",
            " [11.78 11.88]\n",
            " [11.43 11.36]\n",
            " [11.82 11.97]\n",
            " [11.88 11.76]\n",
            " [11.6  11.65]\n",
            " [11.53 11.69]\n",
            " [12.11 12.08]\n",
            " [12.44 12.39]\n",
            " [12.8  12.89]\n",
            " [12.03 12.01]\n",
            " [11.72 11.76]\n",
            " [12.27 12.52]\n",
            " [12.38 12.65]\n",
            " [12.26 12.27]\n",
            " [12.03 11.94]\n",
            " [11.84 11.88]\n",
            " [11.74 11.65]\n",
            " [12.04 12.1 ]\n",
            " [12.91 13.05]\n",
            " [12.19 12.1 ]\n",
            " [12.37 12.44]\n",
            " [11.41 11.35]\n",
            " [11.57 11.53]\n",
            " [11.83 11.91]\n",
            " [11.83 11.83]\n",
            " [12.57 12.67]\n",
            " [12.23 11.87]\n",
            " [11.8  11.85]\n",
            " [12.29 12.17]\n",
            " [11.42 11.43]\n",
            " [12.16 12.19]\n",
            " [11.65 11.6 ]\n",
            " [12.56 12.6 ]\n",
            " [12.12 12.13]\n",
            " [12.34 12.35]\n",
            " [11.7  11.4 ]\n",
            " [12.35 12.47]\n",
            " [12.12 12.15]\n",
            " [11.85 11.59]\n",
            " [11.61 11.73]\n",
            " [11.84 11.88]\n",
            " [12.08 12.09]\n",
            " [11.47 11.35]\n",
            " [11.91 12.07]\n",
            " [11.76 11.75]\n",
            " [11.65 11.92]\n",
            " [12.08 12.07]\n",
            " [11.56 11.74]\n",
            " [12.09 12.08]\n",
            " [12.4  12.32]\n",
            " [11.77 11.77]\n",
            " [11.92 11.98]\n",
            " [12.2  11.96]\n",
            " [12.32 12.23]\n",
            " [12.04 11.85]\n",
            " [12.29 12.21]\n",
            " [12.32 12.29]\n",
            " [11.71 11.74]\n",
            " [11.75 11.98]\n",
            " [12.15 12.12]\n",
            " [11.48 11.48]\n",
            " [11.83 12.21]\n",
            " [11.86 11.91]\n",
            " [12.06 12.09]\n",
            " [12.13 12.13]\n",
            " [11.95 12.01]\n",
            " [12.55 12.72]\n",
            " [11.45 11.38]\n",
            " [12.33 12.36]\n",
            " [11.79 11.91]\n",
            " [11.76 11.8 ]\n",
            " [11.34 11.49]\n",
            " [12.17 12.24]\n",
            " [12.05 11.92]\n",
            " [11.81 11.81]\n",
            " [12.23 12.14]\n",
            " [12.04 11.92]\n",
            " [11.58 11.66]\n",
            " [11.95 11.94]\n",
            " [11.81 12.01]\n",
            " [11.61 11.78]\n",
            " [12.12 12.24]\n",
            " [11.92 11.89]\n",
            " [11.87 11.75]\n",
            " [11.93 11.84]\n",
            " [11.6  11.64]\n",
            " [11.24 11.28]\n",
            " [12.24 12.11]\n",
            " [12.1  12.14]\n",
            " [11.8  11.77]\n",
            " [11.85 11.98]\n",
            " [11.96 12.07]\n",
            " [12.38 12.3 ]\n",
            " [12.66 12.64]\n",
            " [12.73 12.83]\n",
            " [11.71 11.51]\n",
            " [12.35 12.43]\n",
            " [11.73 11.88]\n",
            " [12.13 12.69]\n",
            " [13.03 12.85]\n",
            " [12.56 12.52]\n",
            " [11.98 12.1 ]\n",
            " [12.42 12.41]\n",
            " [11.73 11.93]\n",
            " [11.81 11.81]\n",
            " [11.53 11.45]\n",
            " [12.27 12.28]\n",
            " [12.76 12.77]\n",
            " [12.18 12.18]\n",
            " [11.9  11.7 ]\n",
            " [12.44 12.34]\n",
            " [12.28 12.42]\n",
            " [11.82 11.73]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io4xLRKFWKEj",
        "outputId": "6e06637d-d675-48fd-e955-f3eb796a2dc4"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print('The accuracy is {:.0%}'.format(r2_score(y_test, y_predgrid)))\n",
        "print('The mean squared error is {:.0%}'.format(mean_squared_error(y_test, y_predgrid)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is 87%\n",
            "The mean squared error is 2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veFT_vbfWKEl",
        "outputId": "927ad657-a4f0-4f3f-ca92-aa78e8a3188e"
      },
      "source": [
        "plt.scatter(y_test,y_predgrid)\n",
        "plt.xlabel('Y Test')\n",
        "plt.ylabel('Predicted Y')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_predR' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-58-852bf4843a75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Y Test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted Y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'y_predR' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIe1Gl4IWKEo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQh75NdyWKEq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}